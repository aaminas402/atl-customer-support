{
  "source_url": "tags_data.html",
  "text": "255 docs tagged with \"data\" | Atlan Documentation\nSkip to main content\nAccess archived assets\nLearn about access archived assets.\nAdd contract impact analysis in GitHub\nAdd contract impact analysis in GitHub <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nAdd custom metadata\n<div style={{position: \"relative\", paddingBottom: \"calc(66.33333333333333% + 41px)\", height: 0}}> <iframe src=\"https://demo.arcade.software/1dT1bPneM5fp1O71lb.\nAdd descriptions\nYou can add descriptions to your assets in Atlan, including tables, views, and individual columns. You can even add a description in the form of a [README](/product/integrations). Doing so will enrich your data asset with the relevant contextual information.\nAdd impact analysis in GitLab\nLearn about add impact analysis in gitlab.\nAdd options\n:::warning Who can do this? You must be an admin user in Atlan to create options for custom metadata properties.\nAI and Automation Features\nGuide to Atlan's AI capabilities and automation features for enhanced data governance and productivity.\nAtlan AI security\nAtlan uses [Azure OpenAI Service](https://azure.microsoft.com/en-in/products/cognitive-services/openai-service) to power Atlan AI. Specifically, Atlan uses GPT-4o, a large, pretrained AI model.\nAttach a tag\nAtlan allows users to add [tags](/product/capabilities/governance/tags/concepts/what-are-tags) to assets. You can use them to identify key characteristics of assets or group them together for usage or data protection.\nAutomate data profiling\nâAvailable via the Data Quality Studio package\nCan Atlan read a dump of SQL statements to create lineage?\nAtlan supports column-level lineage generation for cloud data warehouses like Snowflake, Amazon Redshift, Google BigQuery, and more. Atlan [mines SQL queries](/.\nCan I be notified if there is a change in downstream dashboards or a schema drift?\nYou can [create webhooks](/product/integrations/automation/webhooks/how-tos/create-webhooks) in Atlan to configure alerts or triggers for downstream actions for metadata change events, including schema changes. You can also configure alerts for asset creation or deletion events.\nCan I connect to any source with an ODBC/JDBC driver?\nA number of Atlan's [supported connectors](/product/connections/references/connectors-and-capabilities) use a JDBC- or REST API-based approach for metadata extraction.Â If you are attempting to connect to a source with no native integration, [contact Atlan support](/support/submit-request) to share more details about your use case.\nCan I query any DW/DL?\nYou can query any data warehouse (DW) or data lake (DL) if the integration is supported via Atlan's [supported sources](/product/connections/references/supported-sources#data-sources). Once integrated, you will be able to query the underlying data using the [Insights](/product/capabilities/insights/how-tos/query-data) feature.\nCan I turn off sample data preview for the entire organization?\nAtlan recommends that you turn off sample data preview at a connection level. For example, you can configure the [Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake) to prevent users from previewing any Snowflake data.\nConfigure Snowflake data metric functions\nConfigure Snowflake data metric functions <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nConnect data sources for Azure-hosted Atlan instances\nThis document provides recommended solutions for integrating Atlan instances hosted on Microsoft Azure with the following:.\nConnect on-premises databases to Kubernetes\nYou can configure and use [Atlan's metadata-extractor tool](/apps/connectors/database/on-premises-databases/how-tos/set-up-on-premises-database-access) to extract metadata from on-premises databases with Kubernetes deployment architecture, as an alternative to using Docker Compose.\nCrawl Aiven Kafka\nOnce you have [configured the Aiven Kafka permissions](/apps/connectors/messaging/aiven-kafka/how-tos/set-up-aiven-kafka), you can establish a connection between Atlan and Aiven Kafka.\nCrawl Amazon Athena\nTo crawl metadata from Amazon Athena, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Amazon DynamoDB\nOnce you have [configured the Amazon DynamoDB permissions](/apps/connectors/database/amazon-dynamodb/how-tos/set-up-amazon-dynamodb), you can establish a connection between Atlan and Amazon DynamoDB.\nCrawl Amazon MSK\nTo crawl metadata from Amazon MSK, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Amazon QuickSight\nOnce you have [configured the Amazon QuickSight permissions](/apps/connectors/business-intelligence/amazon-quicksight/how-tos/set-up-amazon-quicksight),.\nCrawl Amazon Redshift\nOnce you have configured the [Amazon Redshift access permissions](/apps/connectors/data-warehouses/amazon-redshift/how-tos/set-up-amazon-redshift), you can establish a connection between Atlan and Amazon Redshift.\nCrawl Apache Kafka\nLearn about crawl apache kafka.\nCrawl AWS Glue\nOnce you have configured the [AWS Glue access permissions](/apps/connectors/etl-tools/aws-glue/how-tos/set-up-aws-glue), you can establish a connection between Atlan and AWS Glue.\nCrawl BigID\nConfigure and run the Atlan BigID workflow to crawl metadata from BigID.\nCrawl Confluent Kafka\nLearn about crawl confluent kafka.\nCrawl Confluent Schema Registry\nOnce you have [configured the Confluent Schema Registry access permissions](/apps/connectors/schema/confluent-schema-registry/how-tos/set-up-confluent-schema-registry), you can establish a connection between Atlan and Confluent Schema Registry.\nCrawl CrateDB\nConfigure and run the CrateDB crawler to extract metadata from your database\nCrawl Databricks\nTo crawl metadata from your Databricks instance, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl DataStax Enterprise\nCrawl DataStax Enterprise\nCrawl dbt\nOnce you have [configured a dbt Cloud service token](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-cloud) or [uploaded your dbt Core project files to S3](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-core), you can crawl dbt metadata into Atlan.\nCrawl Domo\nOnce you have [configured the Domo permissions](/apps/connectors/business-intelligence/domo/how-tos/set-up-domo), you can establish a connection between Atlan and Domo.\nCrawl Fivetran\nLearn about crawl fivetran.\nCrawl Google BigQuery\nOnce you have configured the [Google BigQuery user permissions](/apps/connectors/data-warehouses/google-bigquery/how-tos/set-up-google-bigquery), you can establish a connection between Atlan and Google BigQuery.\nCrawl Hive\nTo crawl metadata from Hive, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl IBM Cognos Analytics\nOnce you have [configured the IBM Cognos Analytics permissions](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-ibm-cognos-analytics), you can establish a connection between Atlan and IBM Cognos Analytics.\nCrawl Looker\nOnce you have configured the [Looker user permissions](/apps/connectors/business-intelligence/looker/how-tos/set-up-looker), you can establish a connection between Atlan and Looker.\nCrawl Matillion\nOnce you have [configured the Matillion user permissions](/apps/connectors/etl-tools/matillion/how-tos/set-up-matillion), you can establish a connection between Atlan and Matillion.\nCrawl Metabase\nOnce you have [configured the Metabase user permissions](/apps/connectors/business-intelligence/metabase/how-tos/set-up-metabase), you can establish a connection between Atlan and Metabase.\nCrawl Microsoft Azure Cosmos DB\nOnce you have [configured the Microsoft Azure Cosmos DB permissions](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/set-up-microsoft-azure-cosmos-db), you can establish a connection between Atlan and Microsoft Azure Cosmos DB.\nCrawl Microsoft Azure Data Factory\nOnce you have [configured the Microsoft Azure Data Factory permissions](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/set-up-microsoft-.\nCrawl Microsoft Azure Event Hubs\nOnce you have [configured the Microsoft Azure Event Hubs permissions](/apps/connectors/messaging/microsoft-azure-event-hubs/how-tos/set-up-microsoft-azure-event-hubs), you can establish a connection between Atlan and Microsoft Azure Event Hubs.\nCrawl Microsoft Azure Synapse Analytics\nOnce you have [configured the Microsoft Azure Synapse Analytics permissions](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics), you can establish a connection between Atlan and Microsoft Azure Synapse Analytics.\nCrawl Microsoft Power BI\nOnce you have configured the [Microsoft Power BI user permissions](/apps/connectors/business-intelligence/microsoft-power-bi/how-tos/set-up-microsoft-power-bi), you can establish a connection between Atlan and Microsoft Power BI.\nCrawl Microsoft SQL Server\nOnce you have configured the [Microsoft SQL Server user permissions](/apps/connectors/database/microsoft-sql-server/how-tos/set-up-microsoft-sql-server),.\nCrawl MicroStrategy\nOnce you have [configured the MicroStrategy permissions](/apps/connectors/business-intelligence/microstrategy/how-tos/set-up-microstrategy), you can establish a connection between Atlan and MicroStrategy.\nCrawl Mode\nOnce you have [configured the Mode user permissions](/apps/connectors/business-intelligence/mode/how-tos/set-up-mode), you can establish a connection between Atlan and Mode.\nCrawl MongoDB\nOnce you have [configured the MongoDB permissions](/apps/connectors/database/mongodb/how-tos/set-up-mongodb), you can establish a connection between Atlan and MongoDB.\nCrawl Monte Carlo\nOnce you have [configured the Monte Carlo permissions](/apps/connectors/observability/monte-carlo/how-tos/set-up-monte-carlo), you can establish a connection between Atlan and Monte Carlo.\nCrawl MySQL\nTo crawl metadata from MySQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl on-premises databases\nOnce you have [set up the metadata-extractor tool](/apps/connectors/database/on-premises-databases/how-tos/set-up-on-premises-database-access), you can extract metadata from your on-premises databases using the following steps.\nCrawl on-premises Databricks\nOnce you have [set up the databricks-extractor tool](/apps/connectors/database/on-premises-databases/references/supported-connections-for-on-premises-databases), you can extract metadata from your on-premises Databricks instances by completing the following steps.\nCrawl on-premises IBM Cognos Analytics\nOnce you have [set up the cognos-extractor tool](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-on-premises-ibm-cognos-analytics-access), you can extract metadata from your on-premises IBM Cognos Analytics instances by completing the following steps.\nCrawl on-premises Kafka\nOnce you have [set up the kafka-extractor tool](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access), you can extract metadata from your on-premises Kafka instances by completing the following steps.\nCrawl on-premises Looker\nOnce you have [set up the looker-extractor tool](/apps/connectors/business-intelligence/looker/how-tos/set-up-on-premises-looker-access), you can extract metadata from your on-premises Looker instances using the following steps.\nCrawl on-premises Tableau\nOnce you have [set up the tableau-extractor tool](/apps/connectors/business-intelligence/tableau/how-tos/set-up-on-premises-tableau-access), you can extract metadata from your on-premises Tableau instances by completing the following steps.\nCrawl on-premises ThoughtSpot\nOnce you have [set up the thoughtspot-extractor tool](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-on-premises-thoughtspot-access),.\nCrawl Oracle\nOnce you have configured the [Oracle user permissions](/apps/connectors/database/oracle/how-tos/set-up-oracle#create-user-in-oracle), you can establish a connection between Atlan and Oracle.\nCrawl PostgreSQL\nTo crawl metadata from PostgreSQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl PrestoSQL\nOnce you have configured the [PrestoSQL user permissions](/apps/connectors/database/prestosql/how-tos/set-up-prestosql), you can establish a connection between Atlan and PrestoSQL.\nCrawl Qlik Sense Cloud\nOnce you have [configured the Qlik Sense Cloud permissions](/apps/connectors/business-intelligence/qlik-sense-cloud/how-tos/set-up-qlik-sense-cloud), you can establish a connection between Atlan and Qlik Sense Cloud.\nCrawl Qlik Sense Enterprise on Windows\nOnce you have [configured the Qlik Sense Enterprise on Windows permissions](/apps/connectors/business-intelligence/qlik-sense-enterprise-on-windows/how-tos/how-.\nCrawl Redash\nOnce you have [configured the Redash permissions](/apps/connectors/business-intelligence/redash/how-tos/set-up-redash), you can establish a connection between Atlan and Redash.\nCrawl Redpanda Kafka\nOnce you have [configured the Redpanda Kafka permissions](/apps/connectors/messaging/redpanda-kafka/how-tos/set-up-redpanda-kafka), you can establish a connection between Atlan and Redpanda Kafka.\nCrawl Salesforce\nOnce you have configured the [Salesforce user permissions](/apps/connectors/crm/salesforce/how-tos/set-up-salesforce), you can establish a connection between Atlan and Salesforce.\nCrawl SAP HANA\nOnce you have [configured the SAP HANA permissions](/apps/connectors/database/sap-hana/how-tos/set-up-sap-hana), you can establish a connection between Atlan and SAP HANA.\nCrawl Sigma\nOnce you have [configured the Sigma permissions](/apps/connectors/business-intelligence/sigma/how-tos/set-up-sigma), you can establish a connection between Atlan and Sigma.\nCrawl Sisense\nOnce you have [configured the Sisense permissions](/apps/connectors/business-intelligence/sisense/how-tos/set-up-sisense), you can establish a connection between Atlan and Sisense.\nCrawl Snowflake\nTo crawl metadata from Snowflake, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Soda\nOnce you have [configured the Soda permissions](/apps/connectors/observability/soda/how-tos/set-up-soda), you can establish a connection between Atlan and Soda.\nCrawl Tableau\nTo crawl metadata from Tableau, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Teradata\nOnce you have configured the [Teradata user permissions](/apps/connectors/database/teradata/how-tos/set-up-teradata), you can establish a connection between Atlan and Teradata.\nCrawl ThoughtSpot\nOnce you have [configured the ThoughtSpot permissions](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-thoughtspot), you can establish a connection between Atlan and ThoughtSpot.\nCrawl Trino\nTo crawl metadata from Trino, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCreate announcements\nAdding an announcement to your data asset helps you call attention to an important feature or notify others about a change coming down the pipeline. Since announcements in Atlan display the time stamp and author information, you can easily identify whether an announcement is still relevant and who to ask for questions.\nData Connections and Integration\nComplete guide for connecting Atlan to your data sources, managing integrations, and troubleshooting connection issues.\nData Models\nData models provide a framework to describe how data is structured, organized, and related within a system. It acts as a blueprint for organizations to design their business applications and processes. Data models can be of different types: relational, hierarchical, entity relationship, and network.\nData Pipelines\nLearn how to connect your data pipelines to Atlan. Explore ETL tools, workflow orchestration, and lineage tracking to build a comprehensive view of your data movement.\nDisable data access\n:::warning Who can do this? You will need to be an admin user in Atlan to configure these options.\nDiscovery FAQs\nFrequently asked questions about Atlan's Discovery capabilities.\nDoes lineage only cover calculated fields for Tableau dashboards?\nAtlan displays upstream as well as downstream lineage for [Tableau dashboards](/apps/connectors/business-intelligence/tableau/references/what-does-atlan-crawl-f.\nDownload impacted assets in Microsoft Excel\nOnce you've [connected Atlan with Microsoft Excel](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-microsoft-excel), you can download impacted assets in Microsoft Excel. This can help you assess the downstream impact of any changes made to an upstream asset for [impact analysis](/product/capabilities/lineage/concepts/what-is-lineage#impact-analysis).\nEnable  Snowflake OAuth\nAtlan supports [Snowflake OAuth-based authentication](https://docs.snowflake.com/user-guide/oauth-snowflake-overview) for [Snowflake](/apps/connectors/data-ware.\nEnable  SSO for Amazon Redshift\nYou will need to [create a client application in Okta](https://help.okta.com/en-us/Content/Topics/Apps/Apps_App_Integration_Wizard_OIDC.htm) to use for [configuring the identity provider in AWS](/apps/connectors/data-warehouses/amazon-redshift/how-tos/enable-sso-for-amazon-redshift).\nEnable  SSO for Google BigQuery\nCredentials are used to obtain an access token from Google's authorization servers for authentication in Atlan.\nEnrich Atlan through dbt\nBeyond the default mapped [dbt Cloud](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-cloud) or [dbt Core](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-core) properties, you can update any of Atlan's metadata attributes (except for `name`, `tenantId`, and `qualifiedName`) through your dbt model's `meta` property.\nextract lineage and usage from Databricks\nOnce you have [crawled assets from Databricks](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can retrieve lineage from [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html) and [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics) from [query history](https://docs.databricks.com/api/workspace/queryhistory/list) or system tables. This is supported for all [three authentication methods](/apps/connectors/data-warehouses/databricks/how-tos/set-up-databricks): personal access token, AWS service principal, and Azure service principal.\nextract on-premises Databricks lineage\nOnce you have [set up the databricks-extractor tool](/apps/connectors/data-warehouses/databricks/how-tos/set-up-on-premises-databricks-lineage-extraction), you can extract lineage from your on-premises Databricks instances by completing the following steps.\nFind assets by usage\nData teams often lack clarity on which data assets can be considered trustworthy, whether these are frequently used, the freshness of the data itself, or how critical these are for enrichment and governance.\nHow can I identify an Insights query in my database access log?\nAtlan appends the product name Atlan and a unique ID at the end of each query in a comment. This can help you identify queries from Insights in your database access logs.\nHow can I use personas to update a term in a glossary?\nBy default, any user in Atlan can view all [glossaries](/product/capabilities/governance/glossary/concepts/what-is-a-glossary) and nested categories and terms in the _Glossary_ section.\nImplement OpenLineage in Airflow operators\nIf you're using an Airflow operator supported by OpenLineage, the OpenLineage events will contain input and output details. This means that you do not have to modify your current DAG implementation and Atlan will be able to generate data lineage.\nIntegrate Amazon MWAA/OpenLineage\nTo learn more about OpenLineage, refer to [OpenLineage configuration and facets](/product/connections/references/openlineage-configuration-and-facets).\nIntegrate Apache Airflow/OpenLineage\nTo integrate Apache Airflow/OpenLineage with Atlan, complete the following steps. To learn more about OpenLineage, refer to [OpenLineage configuration and facets](/product/connections/references/openlineage-configuration-and-facets).\nIntegrate Apache Spark/OpenLineage\nAtlan extracts job-level operational metadata from Apache Spark and generates job lineage through OpenLineage. To learn more about OpenLineage, refer to [OpenLineage configuration and facets](/product/connections/references/openlineage-configuration-and-facets).\nIntegrate Atlan with Microsoft Excel\nThe Atlan add-in for Microsoft Excel makes it easy to enrich metadata in bulk for your data assets in Atlan. You can use the Atlan add-in for both the web and desktop versions of Microsoft Excel.\nIntegrate Jira Data Center\nYou will need to [configure an incoming link](https://confluence.atlassian.com/adminjiraserver/configure-an-incoming-link-1115659067.html) with an external application   -  in this case, Atlan. This will allow Atlan to access Jira data, which means that Jira will act as the OAuth provider.\nIntegrate ServiceNow\nIf your Atlan admin has [enabled the governance workflows and inbox module](/product/capabilities/governance/stewardship/how-tos/automate-data-governance) in your Atlan workspace, you can create a ServiceNow integration to allow your users to [grant or revoke data access](/product/capabilities/governance/stewardship/how-tos/automate-data-governance) for governed assets in Atlan or any other data source.\nInterpret usage metrics\nAtlan currently supports usage and popularity metrics for the following connectors:\nLink your account\nTo [export assets to and bulk enrich metadata from](/product/integrations/collaboration/spreadsheets/how-tos/export-assets) a supported spreadsheet tool,.\nLink your ServiceNow account\nTo request or revoke data access through ServiceNow inside Atlan, you may first need to link your ServiceNow account. This is done automatically for the user that [set up the ServiceNow integration](/product/integrations/project-management/servicenow/how-tos/integrate-servicenow), but not for other users.\nManage custom metadata structures\n:::warning Who can do this? You must be an admin user to manage custom metadata structures, including defining new ones.\nManage Databricks tags\nYou must have a [Unity Catalog-enabled workspace](https://docs.databricks.com/en/data-governance/unity-catalog/get-started.html) and SQL warehouse configured to import Databricks tags in Atlan.\nManage Google BigQuery tags\nAtlan imports your [Google BigQuery tags](https://docs.getdbt.com/references/resource-configs/tags) and allows you to update your Google BigQuery assets with the imported tags. Note that object tagging in Google BigQuery currently requires [Enterprise edition or higher](https://cloud.google.com/bigquery/docs/editions-intro#editions_features).\nManage Snowflake tags\nYou can import your Snowflake tags to Atlan through one-way tag sync. The synced Snowflake tags will be matched to corresponding tags in Atlan through case-insensitive name match and your Snowflake assets will be enriched with their synced tags from Snowflake.\nMigrate from dbt to Atlan action\nThe dbt-action is a custom action designed to perform impact analysis on changes to your dbt models in a [GitHub](/apps/connectors/etl-tools/dbt/how-tos/.\nMine Amazon Redshift\nOnce you have [crawled assets from Amazon Redshift](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can mine its query history to construct lineage and retrieve [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics).\nMine Google BigQuery\nOnce you have [crawled assets from Google BigQuery](/apps/connectors/data-warehouses/google-bigquery/how-tos/crawl-google-bigquery), you can mine its query history to construct lineage.\nMine Microsoft Azure Synapse Analytics\nLearn about mine microsoft azure synapse analytics.\nMine queries through S3\nOnce you have crawled assets from a supported connector, you can mine query history.\nMine Snowflake\nOnce you have [crawled assets from Snowflake](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can mine its query history to construct lineage.\nMine Teradata\nOnce you have [crawled assets from Teradata](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can mine its query history to construct lineage.\norder workflows\nThe [order of operations](/product/connections/how-tos/order-workflows#order-of-operations) you run in Atlan is important. Follow the specific workflow sequence outlined below when crawling [data tools](/product/connections/references/supported-sources). The right order particularly ensures that lineage is constructed without needing to rerun crawlers.\nPreflight checks for Amazon Redshift\nBefore [running the Amazon Redshift crawler](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can run [preflight chec.\nPreflight checks for Anomalo\nThis check tests for the validity of the [host name URL and API key](/apps/connectors/observability/anomalo/how-tos/integrate-anomalo) you provided. If Atlan is unable to connect to your Anomalo instance, this may indicate that your credentials are either incorrect or invalid.\nPreflight checks for Databricks\nBefore [running the Databricks crawler](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can run [preflight checks](/product/co.\nPreflight checks for DataStax Enterprise\nPreflight checks for DataStax Enterprise\nPreflight checks for Domo\nAtlan uses the [DataSet API](https://developer.domo.com/portal/72ae9b3e80374-list-data-sets) to fetch dataset metadata from Domo.\nPreflight checks for Fivetran\nLearn about preflight checks for fivetran.\nPreflight checks for Google BigQuery\nEach request requires an OAuth 2.0 access token generated via the [service account key](https://cloud.google.com/docs/authentication#service-accounts).\nPreflight checks for Hive\nBefore [running the Hive crawler](/apps/connectors/database/hive/how-tos/crawl-hive), you can run [preflight checks](/product/connections/concepts/what-a.\nPreflight checks for Metabase\nBefore [running the Metabase crawler](/apps/connectors/business-intelligence/metabase/how-tos/crawl-metabase), you can run [preflight checks](/product/co.\nPreflight checks for Microsoft Azure Data Factory\nBefore [running the Microsoft Azure Data Factory crawler](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/crawl-microsoft-azure-data-fact.\nPreflight checks for Microsoft Azure Synapse Analytics\nThis check is performed for both [basic](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) and [service principal](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) authentication method.\nPreflight checks for Microsoft SQL Server\nBefore [running the Microsoft SQL Server crawler](/apps/connectors/database/microsoft-sql-server/how-tos/crawl-microsoft-sql-server), you can run [prefli.\nPreflight checks for Mode\nBefore [running the Mode crawler](/apps/connectors/business-intelligence/mode/how-tos/crawl-mode), you can run [preflight checks](/product/connections/co.\nPreflight checks for MySQL\nBefore [running the MySQL crawler](/apps/connectors/database/mysql/how-tos/crawl-mysql), you can run [preflight checks](/product/connections/concepts/wha.\nPreflight checks for Oracle\nBefore [running the Oracle crawler](/apps/connectors/database/oracle/how-tos/crawl-oracle), you can run [preflight checks](/product/connections/concepts/.\nPreflight checks for PostgreSQL\nBefore [running the PostgreSQL crawler](/apps/connectors/database/postgresql/how-tos/crawl-postgresql), you can run [preflight checks](/product/connectio.\nPreflight checks for PrestoSQL\nBefore [running the PrestoSQL crawler](/apps/connectors/database/prestosql/how-tos/crawl-prestosql), you can run [preflight checks](/product/connections/.\nPreflight checks for Qlik Sense Cloud\nThis check tests for access to datasets and other Qlik objects.\nPreflight checks for SAP S/4HANA\nPreflight checks for SAP S/4HANA <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nPreflight checks for Snowflake\nBefore [running the Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can run [preflight checks](/product/conne.\nPreflight checks for Soda\nLearn about preflight checks for soda\nPreflight checks for Teradata\nBefore [running the Teradata crawler](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can run [preflight checks](/product/connections/con.\nPreflight checks for Trino\nBefore [running the Trino crawler](/apps/connectors/database/trino/how-tos/crawl-trino), you can run [preflight checks](/product/connections/concepts/wha.\nprovide SSL certificates\nSSL (Secure Sockets Layer) encryption helps establish a secure connection between your data source and Atlan. Atlan currently only supports SSL certificates for [crawling Tableau](/apps/connectors/business-intelligence/tableau/how-tos/crawl-tableau).\nSchedule a query\nYou must [save your query](/product/capabilities/insights/how-tos/save-and-share-queries) before you can schedule it. Your [SMTP configuration](/product/integrations/communication/smtp-and-announcements/how-tos/configure-smtp) must also be in a working state to send results to recipients.\nSearch and discover assets\nAtlan is a living catalog of all your data assets and knowledge. It lets you quickly discover and access your data, along with the tribal knowledge and business context.\nSecurity\nThe Secure Agent is designed with multiple security controls to protect metadata, credentials, and communication between systems. This document outlines its security mechanisms across authentication, encryption, container security, network security, and logging and monitoring.\nSecurity and Compliance\nComplete guide to Atlan's security features, compliance certifications, and data protection capabilities.\nSet up a private network link to Amazon Athena\n:::warning Who can do this? You will need your Amazon Athena or AWS administrator involved - you may not have access yourself to complete these steps.\nSet up Aiven Kafka\nAtlan supports the [S3 extraction method](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access) for fetching metadata from Aiven Kafka. This method uses Atlan's kafka-extractor tool to fetch metadata.\nSet up Amazon DynamoDB\nLearn about set up amazon dynamodb.\nSet up Amazon MSK\nLearn about set up amazon msk.\nSet up Amazon QuickSight\nLearn about set up amazon quicksight.\nSet up Amazon Redshift\n:::warning Who can do this? You will need your Amazon Redshift administrator to run these commands - you may not have access yourself.\nSet up Amazon S3\nCreate AWS IAM permissions and credentials for Atlan to access and catalog your S3 buckets and objects.\nSet up an Azure private network link to Databricks\nFor all details, see [Databricks documentation](https://learn.microsoft.com/en-us/azure/databricks/administration-guide/cloud-configurations/azure/private-link-simplified?source=recommendations#create-the-workspace-and-private-endpoints-in-the-azure-portal-ui).\nSet up Anomalo\nAtlan supports the API authentication method for fetching metadata from [Anomalo](https://docs.anomalo.com/integrations/atlan-integration). This method uses an API key to fetch metadata.\nSet up AWS Glue\nLearn about set up aws glue.\nSet up BigID\nCreate a BigID system user and API token for Atlan integration.\nSet up Confluent Kafka\nAtlan supports the API authentication method for fetching metadata from Confluent Kafka. This method uses an API key and API secret to fetch metadata.\nSet up Confluent Schema Registry\n:::warning Who can do this? You will probably need your Schema Registry administrator to complete these steps - you may not have access yourself.\nSet up Databricks\nAtlan supports three authentication methods for fetching metadata from Databricks. You can set up any of the following authentication methods:.\nSet up DataStax Enterprise\nSet up DataStax Enterprise\nSet up dbt Cloud\n:::warning Who can do this? You will probably need your dbt Cloud administrator to complete these steps - you may not have access yourself.\nSet up Domo\n:::warning Who can do this? You will need your Domo administrator to complete these steps - you may not have access yourself.\nSet up Fivetran\nLearn about set up fivetran.\nSet up Google BigQuery\nYou must be a Google BigQuery administrator to run these commands. For more information, see [Google Cloud's Granting, changing, and revoking access to resources](https://cloud.google.com/iam/docs/granting-changing-revoking-access).\nSet up Google Cloud Storage\nConfigure Google Cloud Storage for secure metadata ingestion with Atlan.\nSet up Hive\n:::warning Who can do this? You will need your Hadoop administrator to run these commands - you may not have access yourself.\nSet up IBM Cognos Analytics\n:::warning Who can do this? You must be an IBM Cognos Analytics administrator to complete these steps - you may not have access yourself.\nSet up Inventory reports\nCreate Inventory report for Amazon S3 in case of inventory based ingestion through the crawler.\nSet up Microsoft Azure Cosmos DB\nIf your Microsoft Azure Cosmos DB deployment includes a mix of vCore- and RU-based accounts, you must configure both to fetch metadata. You can then use the _vCore and RU_ deployment option to [crawl your Microsoft Azure Cosmos DB assets](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/crawl-microsoft-azure-cosmos-db).\nSet up Microsoft Azure Data Factory\nAtlan supports service principal authentication for fetching metadata from Microsoft Azure Data Factory. This method requires a client ID, client secret, and tenant ID to fetch metadata.\nSet up Microsoft Azure Event Hubs\nAtlan supports the following authentication methods for Microsoft Azure Event Hubs:.\nSet up Microsoft Azure Synapse Analytics\nAtlan supports crawling the following with the Microsoft Azure Synapse Analytics package:.\nSet up Microsoft Power BI\nThis guide outlines how to set up Microsoft Power BI so it can connect with Atlan for metadata extraction and lineage tracking.\nSet up Microsoft SQL Server\n:::warning Who can do this? You will probably need your Microsoft SQL Server administrator to run these commands - you may not have access yourself.\nSet up MicroStrategy\nAtlan supports the basic authentication method for fetching metadata from MicroStrategy. This method uses a username and password to fetch metadata.\nSet up MongoDB\nAtlan supports the basic authentication method for fetching metadata from MongoDB. This method uses a [username and password](#create-database-user-in-mongodb) to fetch metadata.\nSet up Monte Carlo\n:::warning Who can do this? You will probably need your Monte Carlo [account owner](https://docs.getmontecarlo.com/docs/authorizationmanaged-roles-and-groups).\nSet up MySQL\n:::warning Who can do this? You will probably need your MySQL administrator to run these commands - you may not have access yourself.\nSet up on-premises database access\nIn such cases you may want to decouple the extraction of metadata from its ingestion in Atlan. This approach gives you full control over your resources and metadata transfer to Atlan.\nSet up on-premises Databricks access\nIn some cases you will not be able to expose your Databricks instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises IBM Cognos Analytics access\n:::warning Who can do this? You will need access to a machine that can run Docker on-premises. You will also need your IBM Cognos Analytics instance details,.\nSet up on-premises Kafka access\nIn some cases you won't be able to expose your Kafka instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Looker access\nIn some cases you won't be able to expose your Looker instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Microsoft Azure Synapse Analytics miner access\nIn some cases you will not be able to expose your Microsoft Azure Synapse Analytics instance for Atlan to [mine query history from the Query Store](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics). For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Tableau access\nIn some cases you may not be able to expose your Tableau instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Teradata miner access\nIn some cases you will not be able to expose your Teradata instance for Atlan to mine query history. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises ThoughtSpot access\nIn some cases you will not be able to expose your ThoughtSpot instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up Oracle\n:::warning Who can do this? You need your Oracle database administrator or a similar role to run these commands - you may not have access yourself.\nSet up PostgreSQL\n:::warning Who can do this? You will probably need your PostgreSQL administrator to run these commands - you may not have access yourself.\nSet up PrestoSQL\nLearn about set up prestosql.\nSet up Redash\n:::warning Who can do this? You will probably need your Redash administrator to complete the following steps - you may not have access yourself.\nSet up Redpanda Kafka\nAtlan supports the [S3 extraction method](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access) for fetching metadata from Redpanda Kafka. This method uses Atlan's kafka-extractor tool to fetch metadata.\nSet up SAP HANA\n:::warning Who can do this? You will probably need your SAP HANA administrator to run these commands - you may not have access yourself.\nSet up Sisense\nAtlan supports the basic authentication method for fetching metadata from Sisense. This method uses a username and password to fetch metadata.\nSet up Snowflake\n:::warning Who can do this? You need your Snowflake administrator to run these commands - you may not have access yourself. :::.\nSet up Soda\n:::warning Who can do this? You will need your [Soda Cloud administrator](https://docs.soda.io/soda-cloud/roles-and-rights.html) to complete these steps -.\nSet up Tableau\n:::warning Who can do this? You will probably need your Tableau administrator to run these commands - you may not have access yourself.\nSet up Teradata\n:::warning Who can do this? You will probably need your Teradata administrator to run these commands - you may not have access yourself.\nSSO integration with PingFederate using SAML\nTo use both IdP- and SP-initiated SSO, add both the URLs mentioned above.\nStar assets\n:::warning Who can do this? Anyone with access to Atlan - admin, member, or guest user - can star assets.\nSupported connections for on-premises databases\nThe metadata-extractor tool supports the following connection types.\nTags and Metadata Management\nComplete guide to managing tags, classifications, and metadata in Atlan for effective data governance and organization.\nTroubleshooting data models\nWhat are the known limitations of data models in Atlan?\nTroubleshooting Jira\nWhat fields are supported when creating tickets or requesting access?\nTroubleshooting lineage\nSo you've crawled your source, and mined the queries, but lineage is missing. Why?\nupdate column metadata in Google Sheets\nOnce you've [connected Atlan with Google Sheets](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-google-sheets), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Google Sheets.\nUpdate column metadata in Microsoft Excel\nOnce you've [connected Atlan with Microsoft Excel](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-microsoft-excel), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Microsoft Excel.\nUse the filters menu\nYou can refine the search for your assets in Atlan using the filters menu. Add filters to your asset search to find assets that are more relevant to you.\nview data models\nOnce you have [ingested your ER model assets in Atlan](/product/capabilities/data-models/concepts/what-are-data-models), you can:.\nView query logs\nYou can also view additional details and run status for each query and use filters to track specific queries. Query logs are persisted throughout the lifecycle of the Atlan instance for your organization.\nWhat are Power BI processes on the lineage graph?\nNote that process entities may not have a counterpart entity in Microsoft Power BI. Consider these to be nodes that you can enrich with metadata to describe the process or relationship between two Microsoft Power BI assets.\nWhat does Atlan crawl from Amazon Athena?\nAtlan crawls and maps the following assets and properties from Amazon Athena.\nWhat does Atlan crawl from Amazon DynamoDB?\nAtlan crawls and maps the following assets and properties from Amazon DynamoDB. Atlan also currently supports lineage between Amazon DynamoDB as a source to supported data warehouses as destinations, as enriched by Fivetran.\nWhat does Atlan crawl from Amazon QuickSight?\nAtlan currently supports lineage for the Amazon QuickSight connector to the following data sources:.\nWhat does Atlan crawl from Amazon Redshift?\nAtlan crawls and maps the following assets and properties from Amazon Redshift.\nWhat does Atlan crawl from Anomalo?\nOnce you have [integrated Anomalo](/apps/connectors/observability/anomalo/how-tos/integrate-anomalo), Atlan will receive webhook events when checks are executed in Anomalo. These checks will be cataloged in Atlan to create a relationship with existing assets using the association information from the check.\nWhat does Atlan crawl from Apache Spark/OpenLineage?\nAtlan maps the following assets and properties from Apache Spark/OpenLineage. Asset lineage support depends on the data sources that OpenLineage supports.\nWhat does Atlan crawl from AWS Glue?\nAtlan crawls and maps the following assets and properties from AWS Glue.\nWhat does Atlan crawl from BigID?\nReference guide for BigID metadata crawled by Atlan.\nWhat does Atlan crawl from Databricks?\nAtlan crawls and maps the following assets and properties from Databricks.\nWhat does Atlan crawl from DataStax Enterprise?\nWhat does Atlan crawl from DataStax Enterprise?\nWhat does Atlan crawl from Domo?\nAtlan supports lineage for the following asset types:.\nWhat does Atlan crawl from Fivetran?\nLearn about what does atlan crawl from fivetran?.\nWhat does Atlan crawl from Google BigQuery?\nAtlan doesn't run any table scans. Atlan leverages the table preview options from [Google BigQuery](https://cloud.google.com/bigquery/docs/best-practices-costs#preview-data)Â that enable you to view data for free and without affecting any quotas using the `tabledata.list` API. Hence, [table](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#tables) asset previews in Atlan are already cost-optimized. However, this doesn't apply to [views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#views) and [materialized views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#materialized-views).\nWhat does Atlan crawl from Hive?\nAtlan crawls and maps the following assets and properties from Hive.\nWhat does Atlan crawl from Microsoft Azure Cosmos DB?\nOnce you have [crawled Microsoft Azure Cosmos DB](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/crawl-microsoft-azure-cosmos-db), you can [.\nWhat does Atlan crawl from Microsoft Azure Data Factory?\nAtlan crawls and maps the following assets and properties from Microsoft Azure Data Factory.\nWhat does Atlan crawl from Microsoft Azure Synapse Analytics?\nAtlan crawls and maps the following assets and properties from Microsoft Azure Synapse Analytics. Atlan also currently supports view-level lineage and cross-source lineage between BI tools and SQL sources.\nWhat does Atlan crawl from Microsoft SQL Server?\nAtlan crawls and maps the following assets and properties from Microsoft SQL Server.\nWhat does Atlan crawl from MongoDB?\nAtlan crawls and maps the following assets and properties from MongoDB. Atlan currently does not support lineage for MongoDB assets.\nWhat does Atlan crawl from MySQL?\nAtlan crawls and maps the following assets and properties from MySQL.\nWhat does Atlan crawl from Oracle?\nAtlan crawls and maps the following assets and properties from Oracle.\nWhat does Atlan crawl from PostgreSQL?\nAtlan crawls and maps the following assets and properties from PostgreSQL.\nWhat does Atlan crawl from PrestoSQL?\nAtlan crawls and maps the following assets and properties from PrestoSQL.\nWhat does Atlan crawl from Qlik Sense Cloud?\nAtlan crawls and maps the following assets and properties from Qlik Sense Cloud.\nWhat does Atlan crawl from SAP ECC?\nWhat does Atlan crawl from SAP ECC? <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nWhat does Atlan crawl from SAP S/4HANA?\nWhat does Atlan crawl from SAP S/4HANA? <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nWhat does Atlan crawl from Sisense?\nAtlan crawls and maps the following assets and properties from Sisense.\nWhat does Atlan crawl from Snowflake?\nAtlan crawls and maps the following assets and properties from Snowflake.\nWhat does Atlan crawl from Soda?\nAtlan crawls datasets and then filters out all the datasets without any checks. It then crawls the checks associated with each of the datasets with checks from Soda. These checks are cataloged in Atlan to create a relationship with existing assets using the association information from the dataset.\nWhat does Atlan crawl from Tableau?\nAtlan crawls and maps the following assets and properties from Tableau.\nWhat does Atlan crawl from Teradata?\nAtlan crawls and maps the following assets and properties from Teradata.\nWhat does Atlan crawl from Trino?\nAtlan crawls and maps the following assets and properties from Trino.\nWhat is included in the Jira integration?\nWith two of your most important workspaces connected, you can save time and improve the way you track issues for your data.\nWhat is included in the Microsoft Teams integration?\nWith two of your most important workspaces connected, you can save time and improve the way you share data assets with your team.\nWhat is included in the Slack integration?\nLearn about the features and capabilities of the Slack integration with Atlan.\nWhat is the default permission for a glossary?\nBy default, users can search and discover [glossaries](/product/capabilities/governance/glossary/concepts/what-is-a-glossary) in Atlan, irrespective of their user role. The rationale being that glossaries are meant to be accessible to all users who want to understand business context. You can define a [glossary policy](/product/capabilities/governance/custom-metadata/how-tos/control-access-metadata-data#glossary-policies) to control what users can do with glossary metadata and [create a persona](/product/capabilities/governance/access-control/how-tos/create-a-persona) to curate edit access.\nWhat is the difference between a Power BI data source and dataflow?\nLearn about what is the difference between a power bi data source and dataflow?.\nWhat lineage does Atlan extract from Matillion?\nAtlan uses Matillion's metadata API to generate lineage associated with [Matillion connectors](https://www.matillion.com/connectors). This is particularly useful for creating lineage between different tools.\nWhat lineage does Atlan extract from Microsoft Azure Data Factory?\nAtlan uses the [Microsoft Azure Data Factory REST API](https://learn.microsoft.com/en-us/rest/api/datafactory/operation-groups?view=rest-datafactory-2018-06-01).\nWhat lineage does Atlan extract from Microsoft Azure Synapse Analytics?\nLearn about what lineage does atlan extract from microsoft azure synapse analytics?.\nWhat lineage does Atlan extract from Microsoft Power BI?\nThis document helps you understand how Atlan generates lineage to upstream SQL sources for your Microsoft Power BI assets using a custom query parser, and the steps you can take while developing reports and dashboards in Microsoft Power BI to create seamless lineage generation.\nWhen does Atlan become a personal data processor or subprocessor?\nAtlan personnel do not have access to any customer instance unless specifically provided by the customer. Accordingly, in the event that a customer instance contains personal data and Atlan personnel are provided access to that instance, Atlan may act as a personal data processor. In addition, depending on whether the customer is a data controller or processor, Atlan may act as a data processor or subprocessor, respectively.\nWhy do I only see tables from the same schema to join from in a visual query?\nWhen [creating a visual query](/product/capabilities/insights/how-tos/query-data), Atlan recommends that you do not select a database or schema in the editor context. Leaving both blank will allow you to discover more tables to join in the Visual Query Builder.\nWhy does the description from Salesforce not show up in Atlan?\nAtlan supports extracting and displaying description metadata for your [Salesforce objects](/apps/connectors/crm/salesforce/references/what-does-atlan-crawl-from-salesforce).\nWhy is lineage available for table level but not column level?\nThe home icon on top of any asset on the [lineage graph](/product/capabilities/lineage/how-tos/view-lineage) indicates the current asset in focus. The lineage view will be different based on the asset you're viewing. To view column-level lineage for [supported sources](/product/connections/references/supported-sources), click **view columns** and then select a column to view data flows for that particular asset.\nWorkflows and Data Processing\nEverything about managing data workflows, understanding lineage generation, and optimizing data processing pipelines in Atlan.",
  "source_type": "docs"
}