{
  "source_url": "tags_connectors.html",
  "text": "299 docs tagged with \"connectors\" | Atlan Documentation\nSkip to main content\nAdd impact analysis in GitHub\nLearn about add impact analysis in github.\nAdd impact analysis in GitLab\nLearn about add impact analysis in gitlab.\nAtlan browser extension security\nLearn about atlan browser extension security.\nAttach a tag\nAtlan allows users to add [tags](/product/capabilities/governance/tags/concepts/what-are-tags) to assets. You can use them to identify key characteristics of assets or group them together for usage or data protection.\nAutomate data profiling\nâAvailable via the Data Quality Studio package\nBulk enrich metadata\nAtlan enables you to use spreadsheet tools to collaborate on assets with your team, make bulk metadata updates, and sync changes back to Atlan.\nCan Atlan integrate with Airflow to generate lineage?\nAtlan currently supports native integration with [Apache Airflow/OpenLineage](/apps/connectors/lineage/apache-airflow-openlineage/how-tos/integrate-apache-airflow-openlineage).\nCan I add Atlan's browser extension for everyone in my organization?\nRefer to [Troubleshooting the Atlan browser extension](/product/integrations/automation/browser-extension/troubleshooting/troubleshooting-atlan-browser-extension).\nCan I connect to any source with an ODBC/JDBC driver?\nA number of Atlan's [supported connectors](/product/connections/references/connectors-and-capabilities) use a JDBC- or REST API-based approach for metadata extraction.Â If you are attempting to connect to a source with no native integration, [contact Atlan support](/support/submit-request) to share more details about your use case.\nCan I turn off sample data preview for the entire organization?\nAtlan recommends that you turn off sample data preview at a connection level. For example, you can configure the [Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake) to prevent users from previewing any Snowflake data.\nCan site renaming affect the Jira integration?\nLearn about can site renaming affect the jira integration?.\nCan the Hive crawler connect to an independent Hive metastore?\nLearn about can the hive crawler connect to an independent hive metastore?.\nCan we use a Microsoft SSO login?\nLearn about can we use a microsoft sso login?.\nConfigure workflow execution\nLearn about configure workflow execution.\nConnect data sources for Azure-hosted Atlan instances\nThis document provides recommended solutions for integrating Atlan instances hosted on Microsoft Azure with the following:.\nConnect on-premises databases to Kubernetes\nYou can configure and use [Atlan's metadata-extractor tool](/apps/connectors/database/on-premises-databases/how-tos/set-up-on-premises-database-access) to extract metadata from on-premises databases with Kubernetes deployment architecture, as an alternative to using Docker Compose.\nConnection issues\nResolve common connection and authentication issues when setting up CrateDB connector\nConnectors\nLearn how to connect your data sources to Atlan. Explore supported connectors, integration patterns, and best practices for unified catalog management.\nConnectors and capabilities\nLearn about connectors and capabilities.\nCrawl Aiven Kafka\nOnce you have [configured the Aiven Kafka permissions](/apps/connectors/messaging/aiven-kafka/how-tos/set-up-aiven-kafka), you can establish a connection between Atlan and Aiven Kafka.\nCrawl Amazon Athena\nTo crawl metadata from Amazon Athena, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Amazon DynamoDB\nOnce you have [configured the Amazon DynamoDB permissions](/apps/connectors/database/amazon-dynamodb/how-tos/set-up-amazon-dynamodb), you can establish a connection between Atlan and Amazon DynamoDB.\nCrawl Amazon MSK\nTo crawl metadata from Amazon MSK, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Amazon QuickSight\nOnce you have [configured the Amazon QuickSight permissions](/apps/connectors/business-intelligence/amazon-quicksight/how-tos/set-up-amazon-quicksight),.\nCrawl Amazon Redshift\nOnce you have configured the [Amazon Redshift access permissions](/apps/connectors/data-warehouses/amazon-redshift/how-tos/set-up-amazon-redshift), you can establish a connection between Atlan and Amazon Redshift.\nCrawl Apache Kafka\nLearn about crawl apache kafka.\nCrawl AWS Glue\nOnce you have configured the [AWS Glue access permissions](/apps/connectors/etl-tools/aws-glue/how-tos/set-up-aws-glue), you can establish a connection between Atlan and AWS Glue.\nCrawl BigID\nConfigure and run the Atlan BigID workflow to crawl metadata from BigID.\nCrawl Confluent Kafka\nLearn about crawl confluent kafka.\nCrawl Confluent Schema Registry\nOnce you have [configured the Confluent Schema Registry access permissions](/apps/connectors/schema/confluent-schema-registry/how-tos/set-up-confluent-schema-registry), you can establish a connection between Atlan and Confluent Schema Registry.\nCrawl CrateDB\nConfigure and run the CrateDB crawler to extract metadata from your database\nCrawl Dagster assets\nCreate a crawler workflow in Atlan to capture lineage from Dagster assets\nCrawl Databricks\nTo crawl metadata from your Databricks instance, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl DataStax Enterprise\nCrawl DataStax Enterprise\nCrawl dbt\nOnce you have [configured a dbt Cloud service token](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-cloud) or [uploaded your dbt Core project files to S3](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-core), you can crawl dbt metadata into Atlan.\nCrawl Domo\nOnce you have [configured the Domo permissions](/apps/connectors/business-intelligence/domo/how-tos/set-up-domo), you can establish a connection between Atlan and Domo.\nCrawl Fivetran\nLearn about crawl fivetran.\nCrawl Google BigQuery\nOnce you have configured the [Google BigQuery user permissions](/apps/connectors/data-warehouses/google-bigquery/how-tos/set-up-google-bigquery), you can establish a connection between Atlan and Google BigQuery.\nCrawl Hive\nTo crawl metadata from Hive, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl IBM Cognos Analytics\nOnce you have [configured the IBM Cognos Analytics permissions](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-ibm-cognos-analytics), you can establish a connection between Atlan and IBM Cognos Analytics.\nCrawl Informatica CDI assets\nConfigure and run the crawler to discover and catalog your Informatica CDI assets\nCrawl Looker\nOnce you have configured the [Looker user permissions](/apps/connectors/business-intelligence/looker/how-tos/set-up-looker), you can establish a connection between Atlan and Looker.\nCrawl Matillion\nOnce you have [configured the Matillion user permissions](/apps/connectors/etl-tools/matillion/how-tos/set-up-matillion), you can establish a connection between Atlan and Matillion.\nCrawl Metabase\nOnce you have [configured the Metabase user permissions](/apps/connectors/business-intelligence/metabase/how-tos/set-up-metabase), you can establish a connection between Atlan and Metabase.\nCrawl Microsoft Azure Cosmos DB\nOnce you have [configured the Microsoft Azure Cosmos DB permissions](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/set-up-microsoft-azure-cosmos-db), you can establish a connection between Atlan and Microsoft Azure Cosmos DB.\nCrawl Microsoft Azure Data Factory\nOnce you have [configured the Microsoft Azure Data Factory permissions](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/set-up-microsoft-.\nCrawl Microsoft Azure Event Hubs\nOnce you have [configured the Microsoft Azure Event Hubs permissions](/apps/connectors/messaging/microsoft-azure-event-hubs/how-tos/set-up-microsoft-azure-event-hubs), you can establish a connection between Atlan and Microsoft Azure Event Hubs.\nCrawl Microsoft Azure Synapse Analytics\nOnce you have [configured the Microsoft Azure Synapse Analytics permissions](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics), you can establish a connection between Atlan and Microsoft Azure Synapse Analytics.\nCrawl Microsoft Power BI\nOnce you have configured the [Microsoft Power BI user permissions](/apps/connectors/business-intelligence/microsoft-power-bi/how-tos/set-up-microsoft-power-bi), you can establish a connection between Atlan and Microsoft Power BI.\nCrawl Microsoft SQL Server\nOnce you have configured the [Microsoft SQL Server user permissions](/apps/connectors/database/microsoft-sql-server/how-tos/set-up-microsoft-sql-server),.\nCrawl MicroStrategy\nOnce you have [configured the MicroStrategy permissions](/apps/connectors/business-intelligence/microstrategy/how-tos/set-up-microstrategy), you can establish a connection between Atlan and MicroStrategy.\nCrawl Mode\nOnce you have [configured the Mode user permissions](/apps/connectors/business-intelligence/mode/how-tos/set-up-mode), you can establish a connection between Atlan and Mode.\nCrawl MongoDB\nOnce you have [configured the MongoDB permissions](/apps/connectors/database/mongodb/how-tos/set-up-mongodb), you can establish a connection between Atlan and MongoDB.\nCrawl Monte Carlo\nOnce you have [configured the Monte Carlo permissions](/apps/connectors/observability/monte-carlo/how-tos/set-up-monte-carlo), you can establish a connection between Atlan and Monte Carlo.\nCrawl MySQL\nTo crawl metadata from MySQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl on-premises databases\nOnce you have [set up the metadata-extractor tool](/apps/connectors/database/on-premises-databases/how-tos/set-up-on-premises-database-access), you can extract metadata from your on-premises databases using the following steps.\nCrawl on-premises Databricks\nOnce you have [set up the databricks-extractor tool](/apps/connectors/database/on-premises-databases/references/supported-connections-for-on-premises-databases), you can extract metadata from your on-premises Databricks instances by completing the following steps.\nCrawl on-premises IBM Cognos Analytics\nOnce you have [set up the cognos-extractor tool](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-on-premises-ibm-cognos-analytics-access), you can extract metadata from your on-premises IBM Cognos Analytics instances by completing the following steps.\nCrawl on-premises Kafka\nOnce you have [set up the kafka-extractor tool](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access), you can extract metadata from your on-premises Kafka instances by completing the following steps.\nCrawl on-premises Looker\nOnce you have [set up the looker-extractor tool](/apps/connectors/business-intelligence/looker/how-tos/set-up-on-premises-looker-access), you can extract metadata from your on-premises Looker instances using the following steps.\nCrawl on-premises Tableau\nOnce you have [set up the tableau-extractor tool](/apps/connectors/business-intelligence/tableau/how-tos/set-up-on-premises-tableau-access), you can extract metadata from your on-premises Tableau instances by completing the following steps.\nCrawl on-premises ThoughtSpot\nOnce you have [set up the thoughtspot-extractor tool](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-on-premises-thoughtspot-access),.\nCrawl Oracle\nOnce you have configured the [Oracle user permissions](/apps/connectors/database/oracle/how-tos/set-up-oracle#create-user-in-oracle), you can establish a connection between Atlan and Oracle.\nCrawl PostgreSQL\nTo crawl metadata from PostgreSQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl PrestoSQL\nOnce you have configured the [PrestoSQL user permissions](/apps/connectors/database/prestosql/how-tos/set-up-prestosql), you can establish a connection between Atlan and PrestoSQL.\nCrawl Qlik Sense Cloud\nOnce you have [configured the Qlik Sense Cloud permissions](/apps/connectors/business-intelligence/qlik-sense-cloud/how-tos/set-up-qlik-sense-cloud), you can establish a connection between Atlan and Qlik Sense Cloud.\nCrawl Qlik Sense Enterprise on Windows\nOnce you have [configured the Qlik Sense Enterprise on Windows permissions](/apps/connectors/business-intelligence/qlik-sense-enterprise-on-windows/how-tos/how-.\nCrawl Redash\nOnce you have [configured the Redash permissions](/apps/connectors/business-intelligence/redash/how-tos/set-up-redash), you can establish a connection between Atlan and Redash.\nCrawl Redpanda Kafka\nOnce you have [configured the Redpanda Kafka permissions](/apps/connectors/messaging/redpanda-kafka/how-tos/set-up-redpanda-kafka), you can establish a connection between Atlan and Redpanda Kafka.\nCrawl Salesforce\nOnce you have configured the [Salesforce user permissions](/apps/connectors/crm/salesforce/how-tos/set-up-salesforce), you can establish a connection between Atlan and Salesforce.\nCrawl SAP HANA\nOnce you have [configured the SAP HANA permissions](/apps/connectors/database/sap-hana/how-tos/set-up-sap-hana), you can establish a connection between Atlan and SAP HANA.\nCrawl Sigma\nOnce you have [configured the Sigma permissions](/apps/connectors/business-intelligence/sigma/how-tos/set-up-sigma), you can establish a connection between Atlan and Sigma.\nCrawl Sisense\nOnce you have [configured the Sisense permissions](/apps/connectors/business-intelligence/sisense/how-tos/set-up-sisense), you can establish a connection between Atlan and Sisense.\nCrawl Snowflake\nTo crawl metadata from Snowflake, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Soda\nOnce you have [configured the Soda permissions](/apps/connectors/observability/soda/how-tos/set-up-soda), you can establish a connection between Atlan and Soda.\nCrawl Tableau\nTo crawl metadata from Tableau, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCrawl Teradata\nOnce you have configured the [Teradata user permissions](/apps/connectors/database/teradata/how-tos/set-up-teradata), you can establish a connection between Atlan and Teradata.\nCrawl ThoughtSpot\nOnce you have [configured the ThoughtSpot permissions](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-thoughtspot), you can establish a connection between Atlan and ThoughtSpot.\nCrawl Trino\nTo crawl metadata from Trino, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.\nCreate README templates\nAdmin users in Atlan can create, curate, and manage README templates from the governance center. Once admin users have created the templates, other users will be able to select these templates and [enrich their assets with READMEs](/product/integrations). They will also be able to see a rich preview of each template before adding the relevant documentation.\nCustom solutions\nLearn about custom solutions.\nDagster integration\nFrequently asked questions about Dagster integration with Atlan\nData Connections and Integration\nComplete guide for connecting Atlan to your data sources, managing integrations, and troubleshooting connection issues.\nData Pipelines\nLearn how to connect your data pipelines to Atlan. Explore ETL tools, workflow orchestration, and lineage tracking to build a comprehensive view of your data movement.\nDelete a connection\nLearn about delete a connection.\nDeployment architecture\nThe Atlan Secure Agent is a Kubernetes-based application that runs within a customer's environment. It acts as a gateway between the single-tenant Atlan SaaS and external systems like Snowflake, Tableau, and other data sources. This document explains the Secure Agent's deployment architecture, key components, communication flows, and security considerations.\nDoes Atlan require an admin user in Salesforce?\nNo. However, it is recommended that a Salesforce administrator establishes a [connection between Atlan and Salesforce](/apps/connectors/crm/salesforce/how-tos/set-up-salesforce). To learn more, see [here](/apps/connectors/crm/salesforce/troubleshooting/troubleshooting-salesforce-connectivity).\nDoes lineage only cover calculated fields for Tableau dashboards?\nAtlan displays upstream as well as downstream lineage for [Tableau dashboards](/apps/connectors/business-intelligence/tableau/references/what-does-atlan-crawl-f.\nDownload impacted assets in Google Sheets\nOnce you've [connected Atlan with Google Sheets](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-google-sheets), you can download impacted assets in Google Sheets. This can help you assess the downstream impact of any changes made to an upstream asset for [impact analysis](/product/capabilities/lineage/concepts/what-is-lineage#impact-analysis).\nEnable  Azure AD for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in Azure AD, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in Azure AD, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  Google for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in Google, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in Google, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  JumpCloud for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in JumpCloud, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in JumpCloud, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  Okta for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in Okta, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in Okta, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  OneLogin for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in OneLogin, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in OneLogin, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  SAML 2.0 for SSO\nSSO group mappings are triggered every time a user authenticates in Atlan. A user may need to log out and then log into Atlan again to view the changes. If a user is added to a new group or removed from an existing one in SAML 2.0, the updates will also be reflected in Atlan. To ensure that the sync is successful, the groups that the user belongs to should be mapped in Atlan, and if a group name has changed in SAML 2.0, you will need to update the group name in Atlan as well. For any questions about group mapping sync, head over [here](/product/integrations/identity-management/sso/troubleshooting/troubleshooting-sso).\nEnable  Snowflake OAuth\nAtlan supports [Snowflake OAuth-based authentication](https://docs.snowflake.com/user-guide/oauth-snowflake-overview) for [Snowflake](/apps/connectors/data-ware.\nEnable  SSO for Amazon Redshift\nYou will need to [create a client application in Okta](https://help.okta.com/en-us/Content/Topics/Apps/Apps_App_Integration_Wizard_OIDC.htm) to use for [configuring the identity provider in AWS](/apps/connectors/data-warehouses/amazon-redshift/how-tos/enable-sso-for-amazon-redshift).\nEnable  SSO for Google BigQuery\nCredentials are used to obtain an access token from Google's authorization servers for authentication in Atlan.\nEnable Okta for SCIM provisioning\nYou can automate the process of provisioning and deprovisioning your Okta users and groups in Atlan with System for Cross-domain Identity Management (SCIM).\nEnrich Atlan through dbt\nBeyond the default mapped [dbt Cloud](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-cloud) or [dbt Core](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-core) properties, you can update any of Atlan's metadata attributes (except for `name`, `tenantId`, and `qualifiedName`) through your dbt model's `meta` property.\nETL tools connectors\nOverview and entry point for all ETL tools connectors in Atlan.\nextract lineage and usage from Databricks\nOnce you have [crawled assets from Databricks](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can retrieve lineage from [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html) and [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics) from [query history](https://docs.databricks.com/api/workspace/queryhistory/list) or system tables. This is supported for all [three authentication methods](/apps/connectors/data-warehouses/databricks/how-tos/set-up-databricks): personal access token, AWS service principal, and Azure service principal.\nextract on-premises Databricks lineage\nOnce you have [set up the databricks-extractor tool](/apps/connectors/data-warehouses/databricks/how-tos/set-up-on-premises-databricks-lineage-extraction), you can extract lineage from your on-premises Databricks instances by completing the following steps.\nFind assets by usage\nData teams often lack clarity on which data assets can be considered trustworthy, whether these are frequently used, the freshness of the data itself, or how critical these are for enrichment and governance.\nHow are product updates deployed?\nLearn about how are product updates deployed?.\nHow can I identify an Insights query in my database access log?\nAtlan appends the product name Atlan and a unique ID at the end of each query in a comment. This can help you identify queries from Insights in your database access logs.\nHow does Atlan handle lineage from Spark jobs?\nLearn about how does atlan handle lineage from spark jobs?.\nImplement OpenLineage in Airflow operators\nIf you're using an Airflow operator supported by OpenLineage, the OpenLineage events will contain input and output details. This means that you do not have to modify your current DAG implementation and Atlan will be able to generate data lineage.\nInfrastructure security\nLearn about infrastructure security.\nIntegrate Amazon MWAA/OpenLineage\nTo learn more about OpenLineage, refer to [OpenLineage configuration and facets](/product/connections/references/openlineage-configuration-and-facets).\nIntegrate Anomalo\nOnce you have [configured the Anomalo settings](/apps/connectors/observability/anomalo/how-tos/set-up-anomalo), you can establish a connection between Atlan and Anomalo.\nIntegrate Apache Airflow/OpenLineage\nTo integrate Apache Airflow/OpenLineage with Atlan, complete the following steps. To learn more about OpenLineage, refer to [OpenLineage configuration and facets](/product/connections/references/openlineage-configuration-and-facets).\nIntegrate Astronomer/OpenLineage\nTo integrate Astronomer/OpenLineage with Atlan, complete the following steps. To learn more about OpenLineage, refer to [OpenLineage configuration and facets](/.\nIntegrate Atlan with Google Sheets\nThe Atlan add-on for Google Sheets makes it easy to edit column metadata in bulk for your data assets in Atlan.\nIntegrate Jira Cloud\nYou must have at least one issue already created in Jira before integrating it with Atlan. This will enable Atlan to detect whether the Atlan app is installed in your Jira workspace for the integration to work.\nIntegrate Microsoft Teams\nOnce you have retrieved the team link, you can proceed to connecting Atlan to Microsoft Teams.\nInterpret usage metrics\nAtlan currently supports usage and popularity metrics for the following connectors:\nIs there a way to build lineage from NetSuite to Snowflake?\nLearn about is there a way to build lineage from netsuite to snowflake?.\nLink your Jira account\nTo create and link Jira issues inside Atlan, you may first need to link your Jira account. This is done automatically for the admin user that [set up the Jira integration](/product/integrations/project-management/jira/how-tos/integrate-jira-cloud), but not for other users.\nLink your Microsoft Teams account\nTo get alerts for [starred assets](/product/capabilities/discovery/how-tos/star-assets) directly delivered to your Microsoft Teams account, you may need to first link your Microsoft Teams account. This is done automatically for the user that [set up the Microsoft Teams integration](/product/integrations/collaboration/microsoft-teams/how-tos/integrate-microsoft-teams), but not for other users.\nLink your Slack account\nTo see previews of Slack messages inside Atlan, you may need to first link your Slack account. This is done automatically for the user that [set up the Slack integration](/product/integrations/collaboration/slack/how-tos/integrate-slack), but not for other users.\nManage connectivity\nOnce you've scheduled or run a workflow you can modify its configuration at any time. The configuration that can be modified may vary by workflow but the general steps remain consistent.\nManage Databricks tags\nYou must have a [Unity Catalog-enabled workspace](https://docs.databricks.com/en/data-governance/unity-catalog/get-started.html) and SQL warehouse configured to import Databricks tags in Atlan.\nManage dbt tags\nAtlan imports your [dbt tags](https://docs.getdbt.com/references/resource-configs/tags) and allows you to update your dbt assets with the imported tags.\nManage Google BigQuery tags\nAtlan imports your [Google BigQuery tags](https://docs.getdbt.com/references/resource-configs/tags) and allows you to update your Google BigQuery assets with the imported tags. Note that object tagging in Google BigQuery currently requires [Enterprise edition or higher](https://cloud.google.com/bigquery/docs/editions-intro#editions_features).\nManage requests\nIf your organization's [Slack account is integrated with Atlan](/product/integrations/collaboration/slack/how-tos/integrate-slack), you will receive Slack notifications when your requests are approved or rejected.\nManage Snowflake tags\nYou can import your Snowflake tags to Atlan through one-way tag sync. The synced Snowflake tags will be matched to corresponding tags in Atlan through case-insensitive name match and your Snowflake assets will be enriched with their synced tags from Snowflake.\nMigrate from dbt to Atlan action\nThe dbt-action is a custom action designed to perform impact analysis on changes to your dbt models in a [GitHub](/apps/connectors/etl-tools/dbt/how-tos/.\nMine Amazon Redshift\nOnce you have [crawled assets from Amazon Redshift](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can mine its query history to construct lineage and retrieve [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics).\nMine Google BigQuery\nOnce you have [crawled assets from Google BigQuery](/apps/connectors/data-warehouses/google-bigquery/how-tos/crawl-google-bigquery), you can mine its query history to construct lineage.\nMine Microsoft Azure Synapse Analytics\nLearn about mine microsoft azure synapse analytics.\nMine Microsoft Power BI\nOnce you have crawled assets from Microsoft Power BI, you can mine its activity events to generate usage metrics.\nMine queries through S3\nOnce you have crawled assets from a supported connector, you can mine query history.\nMine Snowflake\nOnce you have [crawled assets from Snowflake](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can mine its query history to construct lineage.\nMine Teradata\nOnce you have [crawled assets from Teradata](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can mine its query history to construct lineage.\nMonitor connectivity\nAtlan runs its crawlers through an orchestrated set of automated tasks.\nOkta first-time login authentication error\nLearn about why do i get an authentication error when logging in via okta for the first time?.\nOpenLineage configuration and facets\nLearn about openlineage configuration and facets.\norder workflows\nThe [order of operations](/product/connections/how-tos/order-workflows#order-of-operations) you run in Atlan is important. Follow the specific workflow sequence outlined below when crawling [data tools](/product/connections/references/supported-sources). The right order particularly ensures that lineage is constructed without needing to rerun crawlers.\nPermissions and limitations\nFrequently asked questions about CrateDB connector setup, permissions, and limitations\nPreflight checks for Aiven Kafka\nBefore [running the Aiven Kafka crawler](/apps/connectors/messaging/aiven-kafka/how-tos/crawl-aiven-kafka), you can run [preflight checks](/product/conne.\nPreflight checks for Amazon MSK\nBefore [running the Amazon MSK crawler](/apps/connectors/messaging/amazon-msk/how-tos/crawl-amazon-msk), you can run [preflight checks](/product/connecti.\nPreflight checks for Amazon QuickSight\nThe [ListAnalyses](https://docs.aws.amazon.com/quicksight/latest/APIReference/API_ListAnalyses.html) REST API is used to fetch the actual list of analyses for which the user has view permission.\nPreflight checks for Amazon Redshift\nBefore [running the Amazon Redshift crawler](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can run [preflight chec.\nPreflight checks for Anomalo\nThis check tests for the validity of the [host name URL and API key](/apps/connectors/observability/anomalo/how-tos/integrate-anomalo) you provided. If Atlan is unable to connect to your Anomalo instance, this may indicate that your credentials are either incorrect or invalid.\nPreflight checks for Apache Kafka\nBefore [running the Apache Kafka crawler](/apps/connectors/messaging/apache-kafka/how-tos/crawl-apache-kafka), run [preflight checks](/product/connection.\nPreflight checks for Confluent Schema Registry\nBefore [running the Confluent Schema Registry crawler](/apps/connectors/schema/confluent-schema-registry/how-tos/crawl-confluent-schema-registry), you ca.\nPreflight checks for CrateDB\nTechnical validations performed before running the CrateDB crawler to verify connectivity and permissions\nPreflight checks for Databricks\nBefore [running the Databricks crawler](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can run [preflight checks](/product/co.\nPreflight checks for DataStax Enterprise\nPreflight checks for DataStax Enterprise\nPreflight checks for dbt\nThis checks if manifest files are present in the provided bucket and prefix.\nPreflight checks for Domo\nAtlan uses the [DataSet API](https://developer.domo.com/portal/72ae9b3e80374-list-data-sets) to fetch dataset metadata from Domo.\nPreflight checks for Fivetran\nLearn about preflight checks for fivetran.\nPreflight checks for Google BigQuery\nEach request requires an OAuth 2.0 access token generated via the [service account key](https://cloud.google.com/docs/authentication#service-accounts).\nPreflight checks for Hive\nBefore [running the Hive crawler](/apps/connectors/database/hive/how-tos/crawl-hive), you can run [preflight checks](/product/connections/concepts/what-a.\nPreflight checks for Looker\nFirst, the list of projects in the _Include Projects_ and _Exclude Projects_ fields is determined. Next, the [Query Projects](https://developers.looker.com/api/explorer/3.1/methods/Project#get_all_projects) REST API is used to fetch the actual list of projects for which the user has [view capability](https://cloud.google.com/looker/docs/access-control-and-permission-management).\nPreflight checks for Metabase\nBefore [running the Metabase crawler](/apps/connectors/business-intelligence/metabase/how-tos/crawl-metabase), you can run [preflight checks](/product/co.\nPreflight checks for Microsoft Azure Data Factory\nBefore [running the Microsoft Azure Data Factory crawler](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/crawl-microsoft-azure-data-fact.\nPreflight checks for Microsoft Azure Synapse Analytics\nThis check is performed for both [basic](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) and [service principal](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) authentication method.\nPreflight checks for Microsoft Power BI\nBefore [running the Microsoft Power BI crawler](/apps/connectors/business-intelligence/microsoft-power-bi/how-tos/crawl-microsoft-power-bi), you can run.\nPreflight checks for Microsoft SQL Server\nBefore [running the Microsoft SQL Server crawler](/apps/connectors/database/microsoft-sql-server/how-tos/crawl-microsoft-sql-server), you can run [prefli.\nPreflight checks for MicroStrategy\nFirst, the list of projects in the _Include Projects_ and _Exclude Projects_ fields is determined. Next,Â the [Get Projects REST API](https://demo.microstrategy.com/MicroStrategyLibrary/api-docs/index.html#/Projects/getProjects_1) is used to fetch the actual list of projects for which the user has permissions.\nPreflight checks for Mode\nBefore [running the Mode crawler](/apps/connectors/business-intelligence/mode/how-tos/crawl-mode), you can run [preflight checks](/product/connections/co.\nPreflight checks for Monte Carlo\nBefore [running the Monte Carlo crawler](/apps/connectors/observability/monte-carlo/how-tos/crawl-monte-carlo), you can run [preflight checks](/product/c.\nPreflight checks for MySQL\nBefore [running the MySQL crawler](/apps/connectors/database/mysql/how-tos/crawl-mysql), you can run [preflight checks](/product/connections/concepts/wha.\nPreflight checks for Oracle\nBefore [running the Oracle crawler](/apps/connectors/database/oracle/how-tos/crawl-oracle), you can run [preflight checks](/product/connections/concepts/.\nPreflight checks for PostgreSQL\nBefore [running the PostgreSQL crawler](/apps/connectors/database/postgresql/how-tos/crawl-postgresql), you can run [preflight checks](/product/connectio.\nPreflight checks for PrestoSQL\nBefore [running the PrestoSQL crawler](/apps/connectors/database/prestosql/how-tos/crawl-prestosql), you can run [preflight checks](/product/connections/.\nPreflight checks for Qlik Sense Cloud\nThis check tests for access to datasets and other Qlik objects.\nPreflight checks for Redash\nBefore [running the Redash crawler](/apps/connectors/business-intelligence/redash/how-tos/crawl-redash), you can run [preflight checks](/product/connecti.\nPreflight checks for Redpanda Kafka\nBefore [running the Redpanda Kafka crawler](/apps/connectors/messaging/redpanda-kafka/how-tos/crawl-redpanda-kafka), you can run [preflight checks](/prod.\nPreflight checks for Salesforce\nBefore [running the Salesforce crawler](/apps/connectors/crm/salesforce/how-tos/crawl-salesforce), you can run [preflight checks](/product/connections/co.\nPreflight checks for SAP S/4HANA\nPreflight checks for SAP S/4HANA <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nPreflight checks for Sigma\nFirst, the list of workbooks in the _Include Workbooks_Â and _Exclude Workbooks_ fields is determined. Next, the [List Workbooks](https://help.sigmacomputing.com/hc/en-us/articles/4408555666323) REST API is used to fetch the actual list of workbooks for which the user credentials have view permission.\nPreflight checks for Sisense\nAtlan uses the [Folders API](https://sisense.dev/guides/restApi/v1/?platform=linux&spec=L2023.6#/folders) to check if it's responding with a response status code 200.\nPreflight checks for Snowflake\nBefore [running the Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can run [preflight checks](/product/conne.\nPreflight checks for Tableau\nThe [Server Info](https://help.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref_server.htm#server_info) REST API is used to fetch the `restApiVersion` value.\nPreflight checks for Teradata\nBefore [running the Teradata crawler](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can run [preflight checks](/product/connections/con.\nPreflight checks for Trino\nBefore [running the Trino crawler](/apps/connectors/database/trino/how-tos/crawl-trino), you can run [preflight checks](/product/connections/concepts/wha.\nProvide credentials to query data\nLearn about provide credentials to query data.\nProvide credentials to view sample data\nLearn about provide credentials to view sample data.\nprovide SSL certificates\nSSL (Secure Sockets Layer) encryption helps establish a secure connection between your data source and Atlan. Atlan currently only supports SSL certificates for [crawling Tableau](/apps/connectors/business-intelligence/tableau/how-tos/crawl-tableau).\nProvider package versions for OpenLineage\nLearn about provider package versions for openlineage.\nReport on assets\nLearn about report on assets.\nReport on automations\nYou can track asset enrichment through [suggestions from similar assets](/product/integrations/automation/always-on/references/suggestions-from-similar-assets). You can also view top users who have accepted automated suggestions.\nS3 Inventory Report Structure\nExpected folder structure and format for S3 inventory reports used by Atlan's S3 crawler for inventory-based ingestion.\nSet default user roles for SSO\n:::warning Who can do this? You will need to be an admin user and [configure SSO](/product/integrations/identity-management/sso) with a provider first.\nSet up a private network link to Amazon Athena\n:::warning Who can do this? You will need your Amazon Athena or AWS administrator involved - you may not have access yourself to complete these steps.\nSet up a private network link to Hive\nOnce the Atlan team has confirmed the configuration is ready, please continue with the remaining steps.\nSet up a private network link to Trino\n:::warning Who can do this? You will need your AWS administrator involved - you may not have access to run these tasks yourself.\nSet up Aiven Kafka\nAtlan supports the [S3 extraction method](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access) for fetching metadata from Aiven Kafka. This method uses Atlan's kafka-extractor tool to fetch metadata.\nSet up Alteryx\nSet up real-time integration between Alteryx and Atlan using OpenLineage to automatically catalog assets and create lineage when workflows run.\nSet up Amazon DynamoDB\nLearn about set up amazon dynamodb.\nSet up Amazon S3\nCreate AWS IAM permissions and credentials for Atlan to access and catalog your S3 buckets and objects.\nSet up Anomalo\nAtlan supports the API authentication method for fetching metadata from [Anomalo](https://docs.anomalo.com/integrations/atlan-integration). This method uses an API key to fetch metadata.\nSet up AWS Glue\nLearn about set up aws glue.\nSet up BigID\nCreate a BigID system user and API token for Atlan integration.\nSet up client credentials flow\nConfigure Salesforce for OAuth 2.0 client credentials authentication in Atlan.\nSet up Confluent Schema Registry\n:::warning Who can do this? You will probably need your Schema Registry administrator to complete these steps - you may not have access yourself.\nSet up CrateDB\nConfigure authentication and connection settings for CrateDB connector\nSet up Dagster\nConfigure Dagster integration with Atlan to enable asset and lineage capture from your Dagster assets\nSet up dbt Cloud\n:::warning Who can do this? You will probably need your dbt Cloud administrator to complete these steps - you may not have access yourself.\nSet up Domo\n:::warning Who can do this? You will need your Domo administrator to complete these steps - you may not have access yourself.\nSet up Google BigQuery\nYou must be a Google BigQuery administrator to run these commands. For more information, see [Google Cloud's Granting, changing, and revoking access to resources](https://cloud.google.com/iam/docs/granting-changing-revoking-access).\nSet up Google Cloud Storage\nConfigure Google Cloud Storage for secure metadata ingestion with Atlan.\nSet up IBM Cognos Analytics\n:::warning Who can do this? You must be an IBM Cognos Analytics administrator to complete these steps - you may not have access yourself.\nSet up Informatica CDI\nConfigure authentication and user permissions for Informatica Cloud Data Integration connector\nSet up Inventory reports\nCreate Inventory report for Amazon S3 in case of inventory based ingestion through the crawler.\nSet up JWT bearer flow\nConfigure Salesforce for OAuth 2.0 JWT bearer authentication for Atlan.\nSet up Matillion\nConfigure user authentication and permissions in Matillion to enable Atlan to crawl metadata from your Matillion instance.\nSet up Microsoft Azure Event Hubs\nAtlan supports the following authentication methods for Microsoft Azure Event Hubs:.\nSet up Microsoft Azure Synapse Analytics\nAtlan supports crawling the following with the Microsoft Azure Synapse Analytics package:.\nSet up MicroStrategy\nAtlan supports the basic authentication method for fetching metadata from MicroStrategy. This method uses a username and password to fetch metadata.\nSet up Mode\nIf you do not see the prompts to enter details for the user above, you are probably already signed in to Mode. Sign out of Mode first, and then accept the invite in the service account email.\nSet up MongoDB\nAtlan supports the basic authentication method for fetching metadata from MongoDB. This method uses a [username and password](#create-database-user-in-mongodb) to fetch metadata.\nSet up Monte Carlo\n:::warning Who can do this? You will probably need your Monte Carlo [account owner](https://docs.getmontecarlo.com/docs/authorizationmanaged-roles-and-groups).\nSet up on-premises Databricks lineage extraction\nIn some cases you will not be able to expose your Databricks instance for Atlan to extract and ingest lineage. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Microsoft Azure Synapse Analytics miner access\nIn some cases you will not be able to expose your Microsoft Azure Synapse Analytics instance for Atlan to [mine query history from the Query Store](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics). For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up on-premises Teradata miner access\nIn some cases you will not be able to expose your Teradata instance for Atlan to mine query history. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.\nSet up PrestoSQL\nLearn about set up prestosql.\nSet up Redpanda Kafka\nAtlan supports the [S3 extraction method](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access) for fetching metadata from Redpanda Kafka. This method uses Atlan's kafka-extractor tool to fetch metadata.\nSet up Salesforce\nLearn about setting up Salesforce authentication for Atlan.\nSet up Sisense\nAtlan supports the basic authentication method for fetching metadata from Sisense. This method uses a username and password to fetch metadata.\nSet up Snowflake\n:::warning Who can do this? You need your Snowflake administrator to run these commands - you may not have access yourself. :::.\nSet up Teradata\n:::warning Who can do this? You will probably need your Teradata administrator to run these commands - you may not have access yourself.\nSet up ThoughtSpot\n:::warning Who can do this? You will probably need your ThoughtSpot instance administrator to complete these steps - you may not have access yourself.\nSet up username-password flow\nConfigure Salesforce username-password flow for Atlan integration.\nSupported connections for on-premises databases\nThe metadata-extractor tool supports the following connection types.\nSupported sources\nLearn about supported sources.\nTask and crawl issues\nTroubleshoot Informatica CDI task processing and crawling issues with error, cause, and solution guidance.\nTasks, transformations, and lineage\nLearn about supported tasks, transformations, and lineage generation in the Informatica CDI connector\nTransformations\nUnderstand how Informatica Cloud Data Integration transformation logic and business rules are discovered and cataloged in Atlan\nTroubleshooting AWS Glue connectivity\nLearn about troubleshooting aws glue connectivity.\nTroubleshooting connector-specific SSO authentication\nLearn about troubleshooting connector-specific sso authentication.\nTroubleshooting Metabase connectivity\nLearn about troubleshooting metabase connectivity.\nTroubleshooting Microsoft Teams\nWhy do I get an error while adding Atlan to Microsoft Teams?\nTroubleshooting Mode connectivity\nLearn about troubleshooting mode connectivity.\nTroubleshooting Redash connectivity\nLearn about troubleshooting redash connectivity.\nTroubleshooting SCIM provisioning\nLearn about troubleshooting scim provisioning.\nTroubleshooting ServiceNow\nWhy is the security\\_admin role required to complete the ServiceNow integration?\nTroubleshooting Sisense connectivity\nLearn about troubleshooting sisense connectivity.\nTroubleshooting Slack\nWhat do the colors in Slack notifications for modified assets mean?\nTroubleshooting spreadsheets\nWhy do I need admin consent for exporting assets to Microsoft Excel?\nTroubleshooting ThoughtSpot connectivity\nLearn about troubleshooting thoughtspot connectivity.\nupdate column metadata in Google Sheets\nOnce you've [connected Atlan with Google Sheets](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-google-sheets), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Google Sheets.\nUpdate column metadata in Microsoft Excel\nOnce you've [connected Atlan with Microsoft Excel](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-microsoft-excel), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Microsoft Excel.\nView event logs\nEvent logs help you track and debug events received from supported connectors, providing you with greater observability in Atlan. Event logs are currently stored in Atlan for 7 days.\nWhat are user roles?\nLearn about what are user roles?.\nWhat does Atlan crawl from Aiven Kafka?\nAtlan crawls and maps the following assets and properties from Aiven Kafka.\nWhat does Atlan crawl from Amazon MSK?\nAtlan crawls and maps the following assets and properties from Amazon MSK.\nWhat does Atlan crawl from Amazon MWAA/OpenLineage?\nOnce you have [integrated Amazon MWAA/OpenLineage](/apps/connectors/lineage/amazon-mwaa-openlineage/how-tos/integrate-amazon-mwaa-openlineage), you can [.\nWhat does Atlan crawl from Amazon QuickSight?\nAtlan currently supports lineage for the Amazon QuickSight connector to the following data sources:.\nWhat does Atlan crawl from Anomalo?\nOnce you have [integrated Anomalo](/apps/connectors/observability/anomalo/how-tos/integrate-anomalo), Atlan will receive webhook events when checks are executed in Anomalo. These checks will be cataloged in Atlan to create a relationship with existing assets using the association information from the check.\nWhat does Atlan crawl from Apache Airflow/OpenLineage?\nOnce you have [integrated Apache Airflow/OpenLineage](/apps/connectors/lineage/apache-airflow-openlineage/how-tos/integrate-apache-airflow-openlineage),.\nWhat does Atlan crawl from Apache Kafka?\nAtlan crawls and maps the following assets and properties from Apache Kafka.\nWhat does Atlan crawl from Apache Spark/OpenLineage?\nAtlan maps the following assets and properties from Apache Spark/OpenLineage. Asset lineage support depends on the data sources that OpenLineage supports.\nWhat does Atlan crawl from Astronomer/OpenLineage?\nAtlan maps the following assets and properties from Astronomer/OpenLineage. Asset lineage support depends on the [list of operators supported by OpenLineage](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/1.6.0/supported_classes.html).\nWhat does Atlan crawl from BigID?\nReference guide for BigID metadata crawled by Atlan.\nWhat does Atlan crawl from Cloudera Impala?\nLearn about what does atlan crawl from cloudera impala?.\nWhat does Atlan crawl from Confluent Kafka?\nAtlan crawls and maps the following assets and properties from Confluent Kafka.\nWhat does Atlan crawl from Confluent Schema Registry?\nAtlan crawls and maps the following assets and properties from Confluent Schema Registry.\nWhat does Atlan crawl from CrateDB?\nComplete list of CrateDB assets and metadata properties extracted by Atlan during crawling\nWhat does Atlan crawl from Dagster\nLearn about the Dagster metadata that Atlan captures and visualizes\nWhat does Atlan crawl from Fivetran?\nLearn about what does atlan crawl from fivetran?.\nWhat does Atlan crawl from Google BigQuery?\nAtlan doesn't run any table scans. Atlan leverages the table preview options from [Google BigQuery](https://cloud.google.com/bigquery/docs/best-practices-costs#preview-data)Â that enable you to view data for free and without affecting any quotas using the `tabledata.list` API. Hence, [table](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#tables) asset previews in Atlan are already cost-optimized. However, this doesn't apply to [views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#views) and [materialized views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#materialized-views).\nWhat does Atlan crawl from Google Cloud Composer/OpenLineage?\nAtlan maps the following assets and properties from Google Cloud Composer/OpenLineage. Asset lineage support depends on the [list of operators supported by OpenLineage](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/1.6.0/supported_classes.html).\nWhat does Atlan crawl from IBM Cognos Analytics?\nAtlan crawls and maps the following assets and properties from IBM Cognos Analytics.\nWhat does Atlan crawl from Informatica CDI\nUnderstand the metadata and assets discovered during crawling from Informatica Cloud Data Integration\nWhat does Atlan crawl from Matillion?\nAtlan crawls and maps the following assets and properties from Matillion.\nWhat does Atlan crawl from Metabase?\nAtlan crawls and maps the following assets and properties from Metabase.\nWhat does Atlan crawl from Microsoft Azure Cosmos DB?\nOnce you have [crawled Microsoft Azure Cosmos DB](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/crawl-microsoft-azure-cosmos-db), you can [.\nWhat does Atlan crawl from Microsoft Azure Event Hubs?\nAtlan crawls and maps the following assets and properties from Microsoft Azure Event Hubs.\nWhat does Atlan crawl from Microsoft Power BI?\nAtlan crawls and maps the following assets and properties from Microsoft Power BI.\nWhat does Atlan crawl from MicroStrategy?\nAtlan crawls and maps the following assets and properties from MicroStrategy.\nWhat does Atlan crawl from Mode?\nAtlan crawls and maps the following assets and properties from Mode.\nWhat does Atlan crawl from MongoDB?\nAtlan crawls and maps the following assets and properties from MongoDB. Atlan currently does not support lineage for MongoDB assets.\nWhat does Atlan crawl from Monte Carlo?\nWhat does Atlan crawl from Monte Carlo? <Badge variant=\"preview\" text=\"Private Preview\" link=\"/get-started/references/product-release-stages#private-preview\" />\nWhat does Atlan crawl from MySQL?\nAtlan crawls and maps the following assets and properties from MySQL.\nWhat does Atlan crawl from PostgreSQL?\nAtlan crawls and maps the following assets and properties from PostgreSQL.\nWhat does Atlan crawl from Qlik Sense Cloud?\nAtlan crawls and maps the following assets and properties from Qlik Sense Cloud.\nWhat does Atlan crawl from Qlik Sense Enterprise on Windows?\nAtlan crawls and maps the following assets and properties from Qlik Sense Enterprise on Windows.\nWhat does Atlan crawl from Redash?\nAtlan crawls and maps the following assets and properties from Redash.\nWhat does Atlan crawl from Redpanda Kafka?\nAtlan crawls and maps the following assets and properties from Redpanda Kafka.\nWhat does Atlan crawl from Sisense?\nAtlan crawls and maps the following assets and properties from Sisense.\nWhat does Atlan crawl from Snowflake?\nAtlan crawls and maps the following assets and properties from Snowflake.\nWhat does Atlan crawl from Soda?\nAtlan crawls datasets and then filters out all the datasets without any checks. It then crawls the checks associated with each of the datasets with checks from Soda. These checks are cataloged in Atlan to create a relationship with existing assets using the association information from the dataset.\nWhat does Atlan crawl from Tableau?\nAtlan crawls and maps the following assets and properties from Tableau.\nWhat does Atlan crawl from ThoughtSpot?\nOnce you've [crawled ThoughtSpot](/apps/connectors/business-intelligence/thoughtspot/how-tos/crawl-thoughtspot), you can [use connector-specific filters].\nWhat is the crawler logic for a deprecated asset?\nLearn about what is the crawler logic for a deprecated asset?.\nWhat lineage does Atlan extract from Matillion?\nAtlan uses Matillion's metadata API to generate lineage associated with [Matillion connectors](https://www.matillion.com/connectors). This is particularly useful for creating lineage between different tools.\nWhat lineage does Atlan extract from Microsoft Azure Data Factory?\nAtlan uses the [Microsoft Azure Data Factory REST API](https://learn.microsoft.com/en-us/rest/api/datafactory/operation-groups?view=rest-datafactory-2018-06-01).\nWhat lineage does Atlan extract from Microsoft Azure Synapse Analytics?\nLearn about what lineage does atlan extract from microsoft azure synapse analytics?.\nWhat lineage does Atlan extract from Microsoft Power BI?\nThis document helps you understand how Atlan generates lineage to upstream SQL sources for your Microsoft Power BI assets using a custom query parser, and the steps you can take while developing reports and dashboards in Microsoft Power BI to create seamless lineage generation.\nWhat type of user provisioning does Atlan support for SSO integrations?\nAtlan currently supports _System for Cross-domain Identity Management_ (SCIM) capabilities for user provisioning for:.\nWhat's the difference between connecting to Athena and Glue?\nLearn about what's the difference between connecting to athena and glue?.\nWhy did my users not receive an invite email from Atlan?\nIf you have sent an invite from Atlan but your user(s) did not receive it, Atlan recommends the following:.\nWhy do I get an error message when I click on Atlan's browser extension?\nRefer to [Troubleshooting the Atlan browser extension](/product/integrations/automation/browser-extension/troubleshooting/troubleshooting-atlan-browser-extension).\nWhy does the description from Salesforce not show up in Atlan?\nAtlan supports extracting and displaying description metadata for your [Salesforce objects](/apps/connectors/crm/salesforce/references/what-does-atlan-crawl-from-salesforce).\nWhy is Atlan's browser extension not loading?\nRefer to [Troubleshooting the Atlan browser extension](/product/integrations/automation/browser-extension/troubleshooting/troubleshooting-atlan-browser-extension).",
  "source_type": "docs"
}