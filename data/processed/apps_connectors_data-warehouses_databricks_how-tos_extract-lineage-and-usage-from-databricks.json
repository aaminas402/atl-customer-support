{
  "source_url": "apps_connectors_data-warehouses_databricks_how-tos_extract-lineage-and-usage-from-databricks.html",
  "text": "extract lineage and usage from Databricks | Atlan Documentation\nSkip to main content\nOn this page\nOnce you have\ncrawled assets from Databricks\n, you can retrieve lineage from\nUnity Catalog\nand\nusage and popularity metrics\nfrom\nquery history\nor system tables. This is supported for all\nthree authentication methods\n: personal access token, AWS service principal, and Azure service principal.\nBoth Atlan and Databricks strongly recommend using the system tables method to extract\nlineage\nand\nusage and popularity metrics\nfrom Databricks.\ndanger\nUsage and popularity metrics\ncan be retrieved for all Databricks users. However, your Databricks workspace must be\nUnity Catalog-enabled\nfor the retrieval of lineage and usage and popularity metrics to succeed. You may also need to\nupgrade existing tables and views to Unity Catalog\n, as well as reach out to your Databricks account executive to enable lineage in Unity Catalog. (As of publishing, the feature is still in preview from Databricks on AWS and Azure.)\nTo retrieve lineage and usage from Databricks, rev\niew the\norder of operations\nand then complete the following steps.\nSelect the extractor\nâ\nTo select the Databricks lineage and usage extractor:\nIn the top right of any screen, navigate toÂ\nNew\nand then clickÂ\nNew Workflow\n.\nFrom the filters along the top, click\nMiner\n.\nFrom the list of packages, select\nDatabricks Miner\nand click on\nSetup Workflow\n.\nConfigure the lineage extractor\nâ\nChoose your lineage extraction method:\nIn\nREST API\n, Atlan connects to your database and extracts lineage directly.\nIn\nOffline\n, you will need to first\nextract lineage yourself\nand\nmake it available in S3\n.\nIn\nSystem Table\n, Atlan connects to your database and\nqueries system tables\nto extract lineage directly.\nREST API\nâ\nTo configure the Databricks lineage extractor:\nFor\nConnection\n, select the connection to extract. (To select a connection,\nthe crawler\nmust have already run.)\nClick\nNext\nto proceed.\nOffline extraction method\nâ\nAtlan supports the\noffline extraction method\nfor extracting lineage from Databricks This method uses Atlan's databricks-extractor tool to extract lineage. You will need to first\nextract lineage yourself\nand\nmake it available in S3\n.\nTo enter your S3 details:\nFor\nConnection\n, select the connection to extract. (To select a connection,\nthe crawler\nmust have already run.)\nFor\nBucket name\n, enter the name of your S3 bucket.\nFor\nBucket prefix\n, enter the S3 prefix under which all the metadata files exist. These include\nextracted-lineage/result-0.json\n,\nextracted-query-history/result-0.json\n, and so on.\nFor\nBucket region\n, enter the name of the S3 region.\nWhen complete, at the bottom of the screen, click\nNext\n.\nSystem table\nâ\nTo configure the Databricks lineage extractor:\nFor\nConnection\n, select the connection to extract. (To select a connection,\nthe crawler\nmust have already run.)\n*\nExtraction Catalog Type\n:\nDefault\n: Select to fetch lineage from the system catalog and\naccess\nschema.\nCloned_catalog\n: Select to fetch lineage from a cloned catalog and schema.\nBefore proceeding, make sure the following prerequisites are met:\nYou have already created cloned views named\ncolumn_lineage\nand\ntable_lineage\nin your schema.\nIf not, follow the steps in\nCreate cloned views of system tables\n.\nThe\natlan-user\nmust have\nSELECT\npermissions on both views to access lineage data.\nThen, provide values for the following fields:\nCloned Catalog Name\nâ Catalog containing the cloned views.\nCloned Schema Name\nâ Schema containing the cloned views.\nFor\nSQL Warehouse ID\n, enter the\nID you copied from your SQL warehouse\n.\nClick\nNext\nto proceed.\n(Optional) Configure the usage extractor\nâ\nAtlan extracts\nusage and popularity metrics\nfrom:\nQuery history\nSystem tables\nThis feature is currently limited to queries on SQL warehouses   -  queries on interactive clusters are not supported. Additionally, expensive queries and compute costs for Databricks assets are currently unavailable due to limitations of the\nDatabricks APIs\n.\nTo configure the Databricks usage and popularity extractor:\nFor\nFetch Query History and Calculate Popularity\n, click\nYes\nto retrieve\nusage and popularity metrics\nfor your Databricks assets.\nFor\nPopularity Extraction Method\n: Choose one of the following methods to extract usage and popularity metrics::\nClick\nREST API\nto extract usage and popularity metrics from query history.\nClick\nSystem table\nto extract metrics directly from system tables:\nExtraction catalog type for popularity\n: Choose where to fetch popularity data from:\nDefault\n: Uses the system catalog and\nquery\nschema to fetch popularity metrics.\nCloned_catalog\n: Select to fetch popularity from cloned views in a separate catalog and schema.\nBefore proceeding:\nThe\nquery_history\nview must exist in the provided schema.\nThe\natlan-user\nmust have\nSELECT\npermission on the view.\nThen provide:\nCloned Catalog Name\nâ The catalog that contains the\nquery_history\nview.\nCloned Schema Name\nâ The schema that contains the\nquery_history\nview.\nFor more information, see\nCreate cloned views of system tables\n.\nFor\nSQL Warehouse ID\n, enter the\nID you copied from your SQL warehouse\n.\nConfigure the usage extractor: Â Â\nFor\nPopularity Window (days)\n, 30 days is the maximum limit. You can set a shorter popularity window of less than 30 days.\nFor\nStart time\n, choose the earliest date from which to mine query history. If you're using the\noffline extraction method\nto extract query history from Databricks, skip to the next step.\nFor\nExcluded Users\n, type the names of users to be excluded while calculating\nusage metrics\nfor Databricks assets. Press\nenter\nafter each name to add more names.Â\ndanger\nIf running the miner for the first time, Atlan recommends setting a start date around three days prior to the current date and then scheduling it daily to build up to two weeks of query history. Mining two weeks of query history on the first miner run may cause delays. For all subsequent runs, Atlan requires a minimum lag of 24 to 48 hours to capture all the relevant transformations that were part of a session. Learn more about the miner logic\nhere\n.\nRun the extractor\nâ\nTo run the Databricks lineage and popularity extractor, after completing the steps above:\nTo check for any\npermissions or other configuration issues\nbefore running the crawler, click\nPreflight checks\n. This isÂ currently only supported when using REST API and offline extraction methods. If you're using system tables, skip to step 2.\nYou can either:\nTo run the crawler once immediately, at the bottom of the screen, click the\nRun\nbutton.\nTo schedule the crawler to run hourly, daily, weekly, or monthly, at the bottom of the screen, click the\nSchedule Run\nbutton.\nOnce the extractor has completed running, you will see lineage for Databricks assets! ð\nSelect the extractor\nConfigure the lineage extractor\n(Optional) Configure the usage extractor\nRun the extractor",
  "source_type": "docs"
}