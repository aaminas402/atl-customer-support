{
  "source_url": "snippets_workflows_packages_asset-import.html",
  "text": "Asset import package - Developer\nSkip to content\nAsset import package\n¶\nThe\nasset import package\nloads metadata\nfrom a CSV file that matches the format of one extracted using either of the asset\nexport packages (\nbasic\nor\nadvanced\n).\nImport assets from object store\n¶\n2.6.0\nTo import assets directly from the object store:\nJava\nPython\nKotlin\nRaw REST API\nComing soon\nImport assets from the object store\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\nfrom\npyatlan.client.atlan\nimport\nAtlanClient\nfrom\npyatlan.model.packages\nimport\nAssetImport\nfrom\npyatlan.model.assets\nimport\nAsset\nfrom\npyatlan.model.enums\nimport\nAssetInputHandling\nclient\n=\nAtlanClient\n()\nworkflow\n=\n(\nAssetImport\n()\n# (1)\n.\nobject_store\n()\n# (2)\n.\ns3\n(\n# (3)\naccess_key\n=\n\"test-access-key\"\n,\nsecret_key\n=\n\"test-secret-key\"\n,\nbucket\n=\n\"my-bucket\"\n,\nregion\n=\n\"us-west-1\"\n,\n)\n.\nassets\n(\n# (4)\nprefix\n=\n\"/test/prefix\"\n,\nobject_key\n=\n\"assets-test.csv\"\n,\ninput_handling\n=\nAssetInputHandling\n.\nUPSERT\n,\n)\n.\nassets_advanced\n(\n# (5)\nremove_attributes\n=\n[\nAsset\n.\nCERTIFICATE_STATUS\n,\nAsset\n.\nANNOUNCEMENT_TYPE\n],\nfail_on_errors\n=\nTrue\n,\ncase_sensitive_match\n=\nFalse\n,\nfield_separator\n=\n\",\"\n,\nbatch_size\n=\n20\n,\n)\n.\nglossaries\n(\n# (6)\nprefix\n=\n\"/test/prefix\"\n,\nobject_key\n=\n\"glossaries-test.csv\"\n,\ninput_handling\n=\nAssetInputHandling\n.\nUPDATE\n,\n)\n.\nglossaries_advanced\n(\n# (7)\nremove_attributes\n=\n[\nAsset\n.\nCERTIFICATE_STATUS\n,\nAsset\n.\nANNOUNCEMENT_TYPE\n],\nfail_on_errors\n=\nTrue\n,\nfield_separator\n=\n\",\"\n,\nbatch_size\n=\n20\n,\n)\n.\ndata_products\n(\n# (8)\nprefix\n=\n\"/test/prefix\"\n,\nobject_key\n=\n\"data-products-test.csv\"\n,\ninput_handling\n=\nAssetInputHandling\n.\nUPDATE\n,\n)\n.\ndata_product_advanced\n(\n# (9)\nremove_attributes\n=\n[\nAsset\n.\nCERTIFICATE_STATUS\n,\nAsset\n.\nANNOUNCEMENT_TYPE\n],\nfail_on_errors\n=\nTrue\n,\nfield_separator\n=\n\",\"\n,\nbatch_size\n=\n20\n,\n)\n)\n.\nto_workflow\n()\n# (10)\nresponse\n=\nclient\n.\nworkflow\n.\nrun\n(\nworkflow\n)\n# (11)\nThe\nAssetImport\nloads metadata from a CSV file.\nSet up the package to import metadata directly from the object store.\nYou can use different object store methods (e.g:\ns3()\n,\ngcs()\n,\nadls()\n). In this example,\nwe're building a workflow using\ns3()\nand for that, you’ll need to provide the following information:\nAWS access key.\nAWS secret key.\nname of the bucket/storage that contains the metadata CSV files.\nname of the AWS region.\n(Optional) To set up the package for importing assets, provide the following information:\nprefix\n: directory (path) within the object store from\nwhich to retrieve the file containing asset metadata.\nobject_key\n: object key (filename),\nincluding its extension, within the object store and prefix\ninput_handling\n: specifies whether to allow the creation\nof new assets from the input CSV with full (\nAssetInputHandling.UPSERT\n)\nor partial assets (\nAssetInputHandling.PARTIAL\n)\nor only update (\nAssetInputHandling.UPDATE\n) existing assets in Atlan.\n(Optional) To set up the package for importing assets with\nadvanced configuration, provide the following information:\nremove_attributes\n: list of attributes to clear (remove)\nfrom assets if their value is blank in the provided file.\nfail_on_errors\n: specifies whether an invalid value\nin a field should cause the import to fail (\nTrue\n) or\nlog a warning, skip that value, and proceed (\nFalse\n).\ncase_sensitive_match\n: indicates whether to use\ncase-sensitive matching when running in update-only mode (\nTrue\n)\nor to try case-insensitive matching (\nFalse\n).\nis_table_view_agnostic\n: specifies whether to treat\ntables, views, and materialized views as interchangeable (\nTrue\n)\nor to strictly adhere to specified types in the input (\nFalse\n).\nfield_separator\n: character used to separate\nfields in the input file (e.g:\n','\nor\n';'\n).\nbatch_size\n: maximum number of rows\nto process at a time (per API request).\n(Optional) To set up the package for importing glossaries, provide the following information:\nprefix\n: directory (path) within the object store from\nwhich to retrieve the file containing glossaries, categories and terms.\nobject_key\n: object key (filename),\nincluding its extension, within the object store and prefix\ninput_handling\n: specifies whether to allow the creation\nof new glossaries, categories and terms from the input CSV (\nAssetInputHandling.UPSERT\n)\nor or ensure these are only updated (\nAssetInputHandling.UPDATE\n) if they already exist in Atlan.\n(Optional) To set up the package for importing glossaries with\nadvanced configuration, provide the following information:\nremove_attributes\n: list of attributes to clear (remove)\nfrom assets if their value is blank in the provided file.\nfail_on_errors\n: specifies whether an invalid value\nin a field should cause the import to fail (\nTrue\n) or\nlog a warning, skip that value, and proceed (\nFalse\n).\nfield_separator\n: character used to separate\nfields in the input file (e.g:\n','\nor\n';'\n).\nbatch_size\n: maximum number of rows\nto process at a time (per API request).\n(Optional) To set up the package for importing data products, provide the following information:\nprefix\n: directory (path) within the object store from\nwhich to retrieve the file containing data domains, and data products.\nobject_key\n: object key (filename),\nincluding its extension, within the object store and prefix\ninput_handling\n: specifies whether to allow the creation\nof new data domains, and data products from the input CSV (\nAssetInputHandling.UPSERT\n)\nor or ensure these are only updated (\nAssetInputHandling.UPDATE\n) if they already exist in Atlan.\n(Optional) To set up the package for importing data domain\nand data products with advanced configuration, provide the following information:\nremove_attributes\n: list of attributes to clear (remove)\nfrom assets if their value is blank in the provided file.\nfail_on_errors\n: specifies whether an invalid value\nin a field should cause the import to fail (\nTrue\n) or\nlog a warning, skip that value, and proceed (\nFalse\n).\nfield_separator\n: character used to separate\nfields in the input file (e.g:\n','\nor\n';'\n).\nbatch_size\n: maximum number of rows\nto process at a time (per API request).\nConvert the package into a\nWorkflow\nobject.\nRun the workflow by invoking the\nrun()\nmethod\non the workflow client, passing the created object.\nWorkflows run asynchronously\nRemember that workflows run asynchronously.\nSee the\npackages and workflows introduction\nfor details on how to check the status and wait\nuntil the workflow has been completed.\nComing soon\nCreate the workflow via UI only\nWe recommend creating the workflow only via the UI.\nTo rerun an existing workflow, see the steps below.\nRe-run existing workflow\n¶\n2.6.0\nTo re-run an existing asset import workflow:\nJava\nPython\nKotlin\nRaw REST API\nComing soon\nRe-run existing asset import workflow\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\nfrom\npyatlan.client.atlan\nimport\nAtlanClient\nfrom\npyatlan.model.enums\nimport\nWorkflowPackage\nclient\n=\nAtlanClient\n()\nexisting\n=\nclient\n.\nworkflow\n.\nfind_by_type\n(\n# (1)\nprefix\n=\nWorkflowPackage\n.\nASSET_IMPORT\n,\nmax_results\n=\n5\n)\n# Determine which asset import workflow (n)\n# from the list of results you want to re-run.\nresponse\n=\nclient\n.\nworkflow\n.\nrerun\n(\nexisting\n[\nn\n])\n# (2)\nYou can find workflows by their type using the workflow client\nfind_by_type()\nmethod and providing the\nprefix\nfor one of the packages.\nIn this example, we do so for the\nAssetImport\n. (You can also specify\nthe\nmaximum number of resulting workflows\nyou want to retrieve as results.)\nOnce you've found the workflow you want to re-run,\nyou can simply call the workflow client\nrerun()\nmethod.\nOptionally, you can use\nrerun(idempotent=True)\nto avoid re-running a workflow that is already in running or in a pending state.\nThis will return details of the already running workflow if found, and by default, it is set to\nFalse\n.\nWorkflows run asynchronously\nRemember that workflows run asynchronously. See the\npackages and workflows introduction\nfor details on how you can check the status and wait until the workflow has been completed.\nComing soon\nRequires multiple steps through the raw REST API\nFind the existing workflow.\nSend through the resulting re-run request.\nPOST /api/service/workflows/indexsearch\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n{\n\"from\"\n:\n0\n,\n\"size\"\n:\n5\n,\n\"query\"\n:\n{\n\"bool\"\n:\n{\n\"filter\"\n:\n[\n{\n\"nested\"\n:\n{\n\"path\"\n:\n\"metadata\"\n,\n\"query\"\n:\n{\n\"prefix\"\n:\n{\n\"metadata.name.keyword\"\n:\n{\n\"value\"\n:\n\"csa-asset-import\"\n// (1)\n}\n}\n}\n}\n}\n]\n}\n},\n\"sort\"\n:\n[\n{\n\"metadata.creationTimestamp\"\n:\n{\n\"nested\"\n:\n{\n\"path\"\n:\n\"metadata\"\n},\n\"order\"\n:\n\"desc\"\n}\n}\n],\n\"track_total_hits\"\n:\ntrue\n}\nSearching by the\ncsa-asset-import\nprefix will ensure you only find existing asset import workflows.\nName of the workflow\nThe name of the workflow will be nested within the\n_source.metadata.name\nproperty of the response object.\n(Remember since this is a search, there could be multiple results, so you may want to use the other\ndetails in each result to determine which workflow you really want.)\nPOST /api/service/workflows/submit\n100\n101\n102\n103\n104\n{\n\"namespace\"\n:\n\"default\"\n,\n\"resourceKind\"\n:\n\"WorkflowTemplate\"\n,\n\"resourceName\"\n:\n\"csa-asset-import-1684500411\"\n// (1)\n}\nSend the name of the workflow as the\nresourceName\nto rerun it.\n2024-11-20\n2025-01-28\nWas this page helpful?\nThanks for your feedback!\nThanks for your feedback! Help us improve this page by using our\nfeedback form\nto provide us with more information.\nBack to top\nCookie consent\nWe use cookies to:\nAnonymously measure page views, and\nAllow you to give us one-click feedback on any page.\nWe do\nnot\ncollect or store:\nAny personally identifiable information.\nAny information for any (re)marketing purposes.\nWith your consent, you're helping us to make our documentation better 💙\nGoogle Analytics\nAccept\nReject\nManage settings",
  "source_type": "sdk"
}