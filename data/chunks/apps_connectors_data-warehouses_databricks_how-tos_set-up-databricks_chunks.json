[
  {
    "content": "Set up Databricks | Atlan Documentation\nSkip to main content\nOn this page\nAtlan supports three authentication methods for fetching metadata from Databricks. You can set up any of the following authentication methods:\nPersonal access token authentication\nAWS service principal authentication\nAzure service principal authentication\nPersonal access token authentication\nâ\nWho can do this?\nCheck that you have\nAdmin\nand\nDatabricks SQL access\nfor the Databricks workspace. This is required for both cluster options described below. If you don't have this access, contact your Databricks administrator.\nGrant user access to workspace\nâ\nTo grant workspace access to the user creating a personal access token:\nFrom the left menu of the account console, click\nWorkspaces\nand then select a workspace to which you want to add the user.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab.\nIn the upper right of the\nPermissions\npage, click\nAdd permissions\n.\nIn the\nAdd permissions\ndialog, enter the following details:\nFor\nUser, group, or service principal\n, select the user to grant access.\nFor\nPermission\n, click the dropdown and select workspace\nUser.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 0
    }
  },
  {
    "content": ".\nIn the\nAdd permissions\ndialog, enter the following details:\nFor\nUser, group, or service principal\n, select the user to grant access.\nFor\nPermission\n, click the dropdown and select workspace\nUser.\nGenerate a personal access token\nâ\nYou can\ngenerate a personal access token\nin your Databricks workspace to the authenticate the\nintegration in Atlan\n.\nTo generate a personal access token:\nFrom the top right of your Databricks workspace, click your Databricks username, and then from the dropdown, click\nUser\nSettings\n.\nUnder the\nSettings\nmenu, click\nDeveloper\n.\nOn the\nDeveloper\npage, next to\nAccess tokens\n, click\nManage\n.\nOn the\nAccess tokens\npage, click the\nGenerate new token\nbutton.\nIn the\nGenerate new token\ndialog:\nFor\nComment\n, enter a description of the token's intended use - for example,\nAtlan crawler\n.\nFor\nLifetime (days)\n, consider removing the number. This enables the token to be used indefinitely - it won't need to be refreshed.\nImportant!\nIf you do enter a number, remember that you need to periodically regenerate it and update Atlan's crawler configuration with the new token each time.\nAt the bottom of the dialog, click\nGenerate\n.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 1
    }
  },
  {
    "content": "If you do enter a number, remember that you need to periodically regenerate it and update Atlan's crawler configuration with the new token each time.\nAt the bottom of the dialog, click\nGenerate\n.\nCopy and save the generated token in a secure location, and then click\nDone\n.\nSelect a cluster\nâ\nDid you know?\nAtlan recommends using serverless SQL warehouses for instant compute availability. To enable serverless SQL warehouses, refer to\nDatabricks documentation\nfor AWS Databricks workspaces or\nMicrosoft documentation\nfor Azure Databricks workspaces.\nYou can set up personal access token authentication for your Databricks instance using one of the following cluster options:\nInteractive cluster\nSQL warehouse (formerly SQL endpoint)\nInteractive cluster\nâ\nTo confirm an\nall-purpose interactive cluster\nis configured:\nFrom the left menu of any page of your Databricks instance, click\nCompute\n.\nUnder the\nAll-purpose clusters\ntab, verify you have a cluster defined.\nClick the link under the\nName\ncolumn of the table to open your cluster.\nUnder the\nConfiguration\ntab, verify the\nAutopilot options\nto\nTerminate after ... minutes\nis enabled.\nAt the bottom of the\nConfiguration\ntab, expand the",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 2
    }
  },
  {
    "content": "Name\ncolumn of the table to open your cluster.\nUnder the\nConfiguration\ntab, verify the\nAutopilot options\nto\nTerminate after ... minutes\nis enabled.\nAt the bottom of the\nConfiguration\ntab, expand the\nAdvanced options\nexpandable.\nUnder the\nAdvanced options\nexpandable, open the\nJDBC/ODBC\ntab.\nConfirm that all of the fields in this tab are populated, and copy them for use in crawling:\nServer Hostname\n,\nPort\n, and\nHTTP Path\n.\nSQL warehouse (formerly SQL endpoint)\nâ\nTo confirm a\nSQL warehouse\nis configured:\nFrom the left menu of any page of your Databricks instance, open the dropdown just below the\ndatabricks\nlogo and change to\nSQL\n.\nFrom the refreshed left menu, click\nSQL Warehouses\n.\nClick the link under the\nName\ncolumn of the table to open your SQL warehouse.\nUnder the\nConnection details\ntab, confirm that all of the fields are populated and copy them for use in crawling:\nServer hostname\n,\nPort\n, and\nHTTP path\n.\nAWS service principal authentication\nâ\nWho can do this?\nYou need your\nAWS Databricks account admin\nto create a service principal and manage OAuth credentials for the service principal and your\nAWS Databricks workspace admin",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 3
    }
  },
  {
    "content": "â\nWho can do this?\nYou need your\nAWS Databricks account admin\nto create a service principal and manage OAuth credentials for the service principal and your\nAWS Databricks workspace admin\nto add the service principal to your AWS Databricks workspace - you may not have access yourself.\nYou need the following to authenticate the connection in Atlan:\nClient ID\nClient secret\nCreate a service principal\nâ\nYou can create a service principal directly in your Databricks account or from a Databricks workspace.\nIdentity federation enabled on your workspaces: Databricks recommends creating the service principal in the account and assigning it to workspaces.\nIdentity federation disabled on your workspaces: Databricks recommends that you create your service principal from a workspace.\nIdentity federation enabled\nâ\nTo create a service principal from your Databricks account, with identify federation enabled:\nLog in to your Databricks\naccount console\nas an account admin.\nFrom the left menu of the account console, click\nUser management\n.\nFrom the tabs along the top of the\nUser management\npage, click the\nService principals\ntab.\nIn the upper right of the\nService principals\npage, click",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 4
    }
  },
  {
    "content": "User management\n.\nFrom the tabs along the top of the\nUser management\npage, click the\nService principals\ntab.\nIn the upper right of the\nService principals\npage, click\nAdd service principal\n.\nOn the\nAdd service principal\npage, enter a name for the service principal and then click\nAdd\n.\nOnce the service principal has been created, you can assign it to your identity federated workspace. From the left menu of the account console, click\nWorkspaces\nand then select a workspace to which you want to add the service principal.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab.\nIn the upper right of the\nPermissions\npage, click\nAdd permissions\n.\nIn the\nAdd permissions\ndialog, enter the following details:\nFor\nUser, group, or service principal\n, select the service principal you created.\nFor\nPermission\n, click the dropdown and select workspace\nUser.\nIdentity federation disabled\nâ\nTo create a service principal from a Databricks workspace, with identity federation disabled:\nLog in to your AWS Databricks workspace as a workspace admin.\nFrom the top right of your workspace, click your username, and then from the dropdown, click\nAdmin Settings\n.\nIn the left menu of the",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 5
    }
  },
  {
    "content": "Log in to your AWS Databricks workspace as a workspace admin.\nFrom the top right of your workspace, click your username, and then from the dropdown, click\nAdmin Settings\n.\nIn the left menu of the\nSettings\npage, under the\nWorkspace admin\nsubheading, click\nIdentity and access\n.\nOn the\nIdentity and access\npage, under\nManagement and permissions\n, next to\nService principals\n, click\nManage\n.\nIn the upper right of the\nService principals\npage, click\nAdd service principal\n.\nIn the\nAdd service principal\ndialog, click the\nAdd new\nbutton.\nFor\nNew service principal display name\n, enter a name for the service principal and then click\nAdd\n.\nCreate an OAuth secret for the service principal\nâ\nYou need to create an OAuth secret to authenticate to Databricks REST APIs.\nTo create an OAuth secret for the\nservice principal\n:\nLog in to your Databricks\naccount console\nas an account admin.\nFrom the left menu of the account console, click\nUser management\n.\nFrom the tabs along the top of the\nUser management\npage, click the\nService principals\ntab.\nIn the upper right of the\nService principals\npage, select the\nservice principal you created\n.\nOn the service principal page, under\nOAuth secrets\n, click",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 6
    }
  },
  {
    "content": "page, click the\nService principals\ntab.\nIn the upper right of the\nService principals\npage, select the\nservice principal you created\n.\nOn the service principal page, under\nOAuth secrets\n, click\nGenerate secret\n.\nFrom the\nGenerate secret\ndialog, copy the\nSecret\nand\nClient ID\nand store it in a secure location.\ndanger\nNote that this secret is only revealed once during creation. The client ID is the same as the application ID of the service principal.\nOnce you've copied the client ID and secret, click\nDone\n.\nAzure service principal authentication\nâ\nWho can do this?\nYou need your\nAzure Databricks account admin\nto create a service principal and your\nAzure Databricks workspace admin\nto add the service principal to your Azure Databricks workspace - you may not have access yourself.\nYou need the following to authenticate the connection in Atlan:\nClient ID (application ID)\nClient secret\nTenant ID (directory ID)\nCreate a service principal\nâ\nTo\nuse service principals on Azure Databricks\n, an admin user must create a new Microsoft Entra ID (formerly Azure Active Directory) application and then add it to the Azure Databricks workspace to use as a service principal.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 7
    }
  },
  {
    "content": ", an admin user must create a new Microsoft Entra ID (formerly Azure Active Directory) application and then add it to the Azure Databricks workspace to use as a service principal.\nTo create a service principal:\nSign in to the\nAzure portal\n.\nIf you have access to multiple tenants, subscriptions, or directories, click the\nDirectories + subscriptions\n(directory with filter) icon in the top menu to switch to the directory in which you want to create the service principal.\nIn_Search resources, services, and docs_, search for and select\nMicrosoft Entra ID\n.\nClick**+ Add\nand select\nApp registration**.\nFor_Name_, enter a name for the application.\nIn the_Supported account types_section, select\nAccounts in this organizational directory only (Single tenant)\nand then click\nRegister\n.\nOn the application page's_Overview_page, in the_Essentials_section, copy and store the following values in a secure location:\nApplication (client) ID\nDirectory (tenant) ID\nTo generate a client secret, within_Manage_, click\nCertificates & secrets\n.\nOn the_Client secrets_tab, click\nNew client secret\n.\nIn the_Add a client secret_dialog, enter the following details:\nFor\nDescription",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 8
    }
  },
  {
    "content": "Certificates & secrets\n.\nOn the_Client secrets_tab, click\nNew client secret\n.\nIn the_Add a client secret_dialog, enter the following details:\nFor\nDescription\n, enter a description for the client secret.\nFor_Expires_, select an expiry time period for the client secret and then click\nAdd\n.\nCopy and store the client secret's_Value_in a secure place.\nAdd a service principal to your account\nâ\nTo add a service principal to your Azure Databricks account:\nLog in to your\nAzure Databricks account console\nas an account admin.\nFrom the left menu of the account console, click\nUser management\n.\nFrom the tabs along the top of the\nUser management\npage, click the\nService principals\ntab.\nIn the upper right of the\nService principals\npage, click\nAdd service principal\n.\nOn the\nAdd service principal\npage, enter a name for the service principal.\nUnder\nUUID\n, paste the\nApplication (client) ID\nfor the service principal.\nClick\nAdd\n.\nAssign a service principal to a workspace\nâ\nTo add users to a workspace using the account console, the workspace must be enabled for identity federation. Workspace admins can also assign service principals to workspaces using the workspace admin settings page.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 9
    }
  },
  {
    "content": "Identity federation enabled\nâ\nTo assign a service principal to your Azure Databricks account:\nLog in to your Databricks\naccount console\nas an account admin.\nFrom the left menu of the account console, click\nWorkspaces\nand then select a workspace to which you want to add the service principal.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab.\nIn the upper right of the\nPermissions\npage, click\nAdd permissions\n.\nIn the\nAdd permissions\ndialog, enter the following details:\nFor\nUser, group, or service principal\n, select the\nservice principal\nyou created.\nFor\nPermission\n, click the dropdown to select workspace\nUser\n.\nIdentity federation disabled\nâ\nTo assign a service principal to your Azure Databricks workspace:\nLog in to your Azure Databricks workspace as a workspace admin.\nFrom the top right of your workspace, click your username, and then from the dropdown, click\nAdmin Settings\n.\nIn the left menu of the\nSettings\npage, under the\nWorkspace admin\nsubheading, click\nIdentity and access\n.\nOn the\nIdentity and access\npage, under\nManagement and permissions\n, next to\nService principals\n, click\nManage\n.\nIn the upper right of the\nService principals\npage, click",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 10
    }
  },
  {
    "content": "Identity and access\n.\nOn the\nIdentity and access\npage, under\nManagement and permissions\n, next to\nService principals\n, click\nManage\n.\nIn the upper right of the\nService principals\npage, click\nAdd service principal\n.\nIn the\nAdd service principal\ndialog, click the\nAdd new\nbutton.\nFor\nNew service principal display name\n, paste the\nApplication (client) ID\nfor the\nservice principal\n, enter a display name, and then click\nAdd\n.\nGrant permissions to crawl metadata\nâ\nYou must have a Unity Catalog-enabled Databricks workspace to crawl metadata in Atlan.\nTo extract metadata, you can grant the\nBROWSE privilege\n, currently in public preview. You no longer require the\nData Reader\npreset that granted the following privileges on objects in the catalog -\nUSE CATALOG\n,\nUSE SCHEMA\n,\nEXECUTE\n,\nREAD VOLUME\n, and\nSELECT\n.\nTo grant permissions to a user or service principal:\nLog in to your Databricks workspace as a workspace admin.\nFrom the left menu of your workspace, click\nCatalog\n.\nIn the left menu of the\nCatalog Explorer\npage, select the catalog you want to crawl in Atlan.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab and then click the\nGrant\nbutton.\nIn the",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 11
    }
  },
  {
    "content": "Catalog Explorer\npage, select the catalog you want to crawl in Atlan.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab and then click the\nGrant\nbutton.\nIn the\nGrant on (workspace name)\ndialog, configure the following:\nUnder\nPrincipals\n, click the dropdown and then select the user or service principal.\nUnder\nPrivileges\n, check the\nBROWSE\nprivilege.\nAt the bottom of the dialog, click\nGrant\n.\n(Optional) Repeat steps 3-5 for each catalog you want to crawl in Atlan.\nSystem tables extraction method\nâ\nTo crawl metadata via system tables, you must have a Unity Catalog-enabled workspace and a configured SQL warehouse. Follow these steps to extract metadata using system tables:\nCreate one of the following authentication methods:\nPersonal access token\nAWS service principal\nAzure service principal\nGrant the following privileges to the identity you created:\nCAN_USE\non a SQL warehouse\nUSE CATALOG\non\nsystem\ncatalog\nUSE SCHEMA\non\nsystem.information_schema\nSELECT\non the following tables:\nsystem.information_schema.catalogs\nsystem.information_schema.schemata\nsystem.information_schema.tables\nsystem.information_schema.columns\nsystem.information_schema.key_column_usage",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 12
    }
  },
  {
    "content": "system.information_schema.catalogs\nsystem.information_schema.schemata\nsystem.information_schema.tables\nsystem.information_schema.columns\nsystem.information_schema.key_column_usage\nsystem.information_schema.table_constraints\nCross-workspace extraction\nâ\nTo crawl metadata from all workspaces within a Databricks metastore using a single connection, see\nSet up cross-workspace extraction\nfor instructions.\n(Optional) Grant permissions to query and preview data\nâ\ndanger\nAtlan currently only supports\nquerying data\nand\nviewing sample data preview\nfor the\npersonal access token\nauthentication method.\nTo grant permissions to query data and preview example data:\nLog in to your Databricks workspace as a workspace admin.\nFrom the left menu of your workspace, click\nCatalog\n.\nIn the left menu of the\nCatalog Explorer\npage, select the catalog you want to query and preview data from in Atlan.\nFrom the tabs along the top of your workspace page, click the\nPermissions\ntab and then click the\nGrant\nbutton.\nIn the\nGrant on (workspace name)\ndialog, configure the following:\nUnder\nPrincipals\n, click the dropdown and then select the user or service principal.\nUnder\nPrivilege presets",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 13
    }
  },
  {
    "content": "Grant\nbutton.\nIn the\nGrant on (workspace name)\ndialog, configure the following:\nUnder\nPrincipals\n, click the dropdown and then select the user or service principal.\nUnder\nPrivilege presets\n, click the dropdown and then click\nData Reader\nto enable read-only access to the catalog. Doing so automatically selects the following privileges -\nUSE CATALOG\n,\nUSE SCHEMA\n,\nEXECUTE\n,\nREAD VOLUME\n, and\nSELECT\n.\nAt the bottom of the dialog, click\nGrant\n.\n(Optional) Repeat steps 3-5 for each catalog you want to query and preview data from in Atlan.\n(Optional) Grant permissions to import and update tags\nâ\nTo\nimport Databricks tags\n, you must have a Unity Catalog-enabled workspace and a SQL warehouse configured. Atlan supports importing Databricks tags using system tables for all three authentication methods.\nOnce you have created a\npersonal access token\n, an\nAWS service principal\n, or an\nAzure service principal\n, you will need to grant the following privileges:\nCAN_USE\non a SQL warehouse\nUSE CATALOG\non\nsystem catalog\nUSE SCHEMA\non\nsystem.information_schema\nSELECT\non the following tables:\nsystem.information_schema.catalog_tags\nsystem.information_schema.schema_tags",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 14
    }
  },
  {
    "content": "on a SQL warehouse\nUSE CATALOG\non\nsystem catalog\nUSE SCHEMA\non\nsystem.information_schema\nSELECT\non the following tables:\nsystem.information_schema.catalog_tags\nsystem.information_schema.schema_tags\nsystem.information_schema.table_tags\nsystem.information_schema.column_tags\nTo push tags updated for assets in Atlan to Databricks, you need to grant the following\nprivileges\n:\nAPPLY TAG\non the object\nUSE CATALOG\non the object's parent catalog\nUSE SCHEMA\non the object's parent schema\n(Optional) Grant permissions to extract lineage and usage from system tables\nâ\nYou must have a Unity Catalog-enabled workspace to use system tables.\nAtlan supports extracting the following for your Databricks assets using\nsystem tables\n:\nlineage\nusage and popularity metrics\nEnable system.access schema\nâ\nYou need your account admin to enable the\nsystem.access\nschema using the\nSystemSchemas API\n. This enables Atlan to extract lineage using system tables.\nIn Atlan, one Databricks connection corresponds to one metastore. Repeat the following process for each metastore in your Databricks environment for which you want to extract lineage.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 15
    }
  },
  {
    "content": "In Atlan, one Databricks connection corresponds to one metastore. Repeat the following process for each metastore in your Databricks environment for which you want to extract lineage.\nTo verify that system schemas are enabled for each schema, follow the steps in\nDatabricks documentation\n:\nList system schemas\nusing the SystemSchemas API to check the status.\nIf enabled for any given schema, the\nstate\nis\nEnableCompleted\n. This confirms that the schema has been enabled for that specific metastore.\nAtlan can only extract lineage using system tables when the state is marked as\nEnableCompleted\n.\n(Optional) enable\nsystem.information_schema.table\nâ\nTo generate lineage with the target type set as\nPATH\nfor a table, Atlan uses metadata from\nsystem.information_schema.table\nto resolve table paths and dependencies. To enable this, you must grant the following permissions on the relevant catalog, schema, and tables.\nGrant permissions\nâ\nWho can do this?\nYou must be a metastore admin, have the\nMANAGE\nprivilege on the object, or be the owner of the catalog, schema, or table to grant these permissions.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 16
    }
  },
  {
    "content": "Grant permissions\nâ\nWho can do this?\nYou must be a metastore admin, have the\nMANAGE\nprivilege on the object, or be the owner of the catalog, schema, or table to grant these permissions.\nIn Atlan, one Databricks connection corresponds to one metastore. Repeat the following process for each metastore from which you want to extract lineage.\nOpen\nCatalog Explorer\nin your Databricks workspace.\nNavigate to the catalog (for example,\nmain\n) and then to the appropriate schema (for example,\nsales\n).\nClick the\nPermissions\ntab.\nClick\nGrant\n.\nEnter the user or group name (principal).\nAssign the following permissions:\nUSAGE\non the catalog\nUSAGE\non the schema\nSELECT\non each relevant table\nClick\nGrant\nto apply the changes.\nThese privileges enable Atlan to read table definitions and other metadata from the metastore.\n(Optional) enable system.query schema\nâ\nThis is only required if you also want to extract\nusage and popularity metrics\nfrom Databricks.\nYou need your account admin to enable the\nsystem.query\nschema using the\nSystemSchemas API\n. This enables Atlan to mine query history using system tables for usage and popularity metrics.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 17
    }
  },
  {
    "content": "You need your account admin to enable the\nsystem.query\nschema using the\nSystemSchemas API\n. This enables Atlan to mine query history using system tables for usage and popularity metrics.\nTo verify that system schemas is enabled for each schema, follow the steps in\nDatabricks documentation\n. If enabled for any given schema, the\nstate\nis\nEnableCompleted\n.\ninfo\nðª\nDid you know?\nCan't grant\nSELECT\npermissions on the system tables in\nsystem.access\nand\nsystem.query\n? Skip the previous steps and create cloned views in a separate catalog and schema. See\nCreate cloned views of system tables\n.\nGrant permissions\nâ\nAtlan supports extracting Databricks lineage and usage and popularity metrics using system tables for\nall three authentication methods\n.\nOnce you have created a\npersonal access token\n, an\nAWS service principal\n, or an\nAzure service principal\n, you will need to grant the following permissions:\nCAN_USE\non a SQL warehouse\nUSE_CATALOG\non\nsystem\ncatalog\nUSE SCHEMA\non\nsystem.access\nschema\nUSE SCHEMA\non\nsystem.query\nschema (tomine query history for usage and popularity metrics)\nSELECT\non the following tables:\nsystem.query.history",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 18
    }
  },
  {
    "content": "on\nsystem\ncatalog\nUSE SCHEMA\non\nsystem.access\nschema\nUSE SCHEMA\non\nsystem.query\nschema (tomine query history for usage and popularity metrics)\nSELECT\non the following tables:\nsystem.query.history\n(to mine query history for usage and popularity metrics)\nsystem.access.table_lineage\nsystem.access.column_lineage\nYou need to\ncreate a Databricks connection in Atlan\nfor each metastore. You can use the hostname of your Unity Catalog-enabled workspace as the\nHost\nfor the connection.\ninfo\nðª\nDid you know?\nCan't grant\nSELECT\npermissions on the system tables in\nsystem.access\nand\nsystem.query\n? Skip the previous steps and create cloned views in a separate catalog and schema. See\nCreate cloned views of system tables\n.\n(Optional) Create cloned views of system tables\nâ\nWhen you don't want to grant access to system tables directly, you can create cloned views to expose lineage and popularity metrics through a separate schema.\nFollow these steps to set up cloned views:\nCreate a catalog and schema to store cloned views. Use meaningful and unique namesâfor example,\natlan_cloned_catalog\nand\natlan_cloned_schema\n.\nCreate cloned views for the following system tables:\nLineage tables\nCREATE\nOR",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 19
    }
  },
  {
    "content": "atlan_cloned_catalog\nand\natlan_cloned_schema\n.\nCreate cloned views for the following system tables:\nLineage tables\nCREATE\nOR\nREPLACE\nVIEW\n<\ncloned\n-\ncatalog\n-\nname\n>\n.\n<\ncloned\n-\nschema\n-\nname\n>\n.\ncolumn_lineage\nAS\nSELECT\n*\nFROM\nsystem\n.\naccess\n.\ncolumn_lineage\n;\nCREATE\nOR\nREPLACE\nVIEW\n<\ncloned\n-\ncatalog\n-\nname\n>\n.\n<\ncloned\n-\nschema\n-\nname\n>\n.\ntable_lineage\nAS\nSELECT\n*\nFROM\nsystem\n.\naccess\n.\ntable_lineage\n;\nReplace\n<cloned-catalog-name>\nand\n<cloned-schema-name>\nwith the catalog and schema names used in your environment.\nPopularity metrics\nCREATE\nOR\nREPLACE\nVIEW\n<\ncloned\n-\ncatalog\n-\nname\n>\n.\n<\ncloned\n-\nschema\n-\nname\n>\n.\nquery_history\nAS\nSELECT\n*\nFROM\nsystem\n.\nquery\n.\nhistory\n;\nReplace\n<cloned-catalog-name>\nand\n<cloned-schema-name>\nwith the catalog and schema names used in your environment.\nGrant permissions\nâ\nGrant the following permissions to enable access to the cloned views:\nCAN_USE\non a SQL warehouse\nUSE CATALOG\non the catalog (for example,\n<cloned-catalog-name>\n)\nUSE SCHEMA\nand\nSELECT\non the schema (for example,\n<cloned-catalog-name>.<cloned-schema-name>\n)\nYou must\ncreate a Databricks connection in Atlan",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 20
    }
  },
  {
    "content": "on the catalog (for example,\n<cloned-catalog-name>\n)\nUSE SCHEMA\nand\nSELECT\non the schema (for example,\n<cloned-catalog-name>.<cloned-schema-name>\n)\nYou must\ncreate a Databricks connection in Atlan\nfor each metastore. You can use the hostname of your Unity Catalog-enabled workspace as the\nHost\nfor the connection.\nLocate warehouse ID\nâ\nTo extract lineage and usage and popularity metrics using system tables, you will also need the\nwarehouse ID of your SQL warehouse\n.\nTo locate the warehouse ID:\nLog in to your Databricks workspace as a workspace admin.\nFrom the left menu of your workspace, click\nSQL Warehouses\n.\nOn the\nCompute\npage, select the warehouse you want to use.\nFrom the\nOverview\ntab of your warehouse page, next to the\nName\nof your warehouse, copy the value for your SQL warehouse\nID\n. For example,\nexample-warehouse (ID: 123ab4c5def67890)\n, copy the value\n123ab4c5def67890\nand store it in a secure location.\n(Optional) Grant view permissions to access Databricks entities via APIs\nâ",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 21
    }
  },
  {
    "content": "example-warehouse (ID: 123ab4c5def67890)\n, copy the value\n123ab4c5def67890\nand store it in a secure location.\n(Optional) Grant view permissions to access Databricks entities via APIs\nâ\nAtlan uses Databricks REST APIs to extract metadata for Notebooks, Queries, Jobs, and Pipelines. This information helps to understand which Databricks enitity was used to create a lineage between assets. Use the steps below for each object type to grant\nCAN VIEW\npermission to the Databricks user or service principal configured in your integration:\nNotebook API\n(\n/api/2.0/workspace/list\n): Grant\nCAN VIEW\npermission on individual notebooks, or on the workspace folder containing the notebooks, or on the entire workspace. For more information, see\nManage Access Control Lists with Folders\n.\nQueries API\n(\n/api/2.0/sql/queries\n): Grant\nCAN VIEW\npermission on individual queries, or on the workspace folder containing the queries, or on the entire workspace. For more information, see\nView Queries\n.\nJob API\n(\n/api/2.2/jobs/list\n): Grant\nCAN VIEW\npermission on each job object directly.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 22
    }
  },
  {
    "content": "View Queries\n.\nJob API\n(\n/api/2.2/jobs/list\n): Grant\nCAN VIEW\npermission on each job object directly.\nDatabricks Jobs are distinct from notebooks or files and require permission set directly on the job object. For more information, see\nControl Access to a Job\n.\nPipeline API\n(\n/api/2.0/pipelines\n): Grant\nCAN VIEW\npermission on each Delta Live Tables (DLT) pipeline object directly. For more information, see\nConfigure Pipeline Permissions\n.\n(Optional) Grant permissions for views and materialized views\nâ\nAtlan requires the following permissions to to extract view definitions from and generate lineagefor views and materialized views:\nLog in to your Databricks workspace as a workspace admin.\nFrom the left menu of your workspace, click\nCatalog\n.\nIn the\nCatalog Explorer\n, select the catalog you want to extract view definitions from and generate lineage for in Atlan.\nFrom the tabs at the top, click the\nPermissions\ntab, and then click\nGrant\n.\nIn the\nGrant on (workspace name)\ndialog, configure the following:\nSelect the\nuser\nor\nservice principal\nunder\nPrincipals\n.\nSelect the following privileges under\nPrivilege presets\n:\nUSE CATALOG\nUSE SCHEMA\nSELECT\nClick\nGrant\nto apply the permissions.",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 23
    }
  },
  {
    "content": "Select the\nuser\nor\nservice principal\nunder\nPrincipals\n.\nSelect the following privileges under\nPrivilege presets\n:\nUSE CATALOG\nUSE SCHEMA\nSELECT\nClick\nGrant\nto apply the permissions.\nRepeat steps 3â6 for each catalog you want to crawl in Atlan.\nDid you know?\nSELECT\npermission is required to extract the definitions of views and materialized views. If you prefer not to grant\nSELECT\nat the catalog level, you can grant it on individual views and materialized views instead.\n(Optional) Grant permissions to mine query history\nâ\nTo\nmine query history\nusing REST API, you will need to assign the\nCAN MANAGE\npermission on your SQL warehouses to the user or service principal.\nTo grant permissions to mine query history:\nLog in to your Databricks workspace as a workspace admin.\nFrom the left menu of your workspace, click\nSQL Warehouses\n.\nOn the\nCompute\npage, for each SQL warehouse you want to mine query history, click the 3-dot icon and then click\nPermissions\n.\nIn the\nManage permissions\ndialog, configure the following:\nIn the\nType to add multiple users or groups\nfield, search for and select a user or service principal.\nExpand the\nCan use\npermissions dropdown and then select\nCan manage",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 24
    }
  },
  {
    "content": "In the\nType to add multiple users or groups\nfield, search for and select a user or service principal.\nExpand the\nCan use\npermissions dropdown and then select\nCan manage\n. This permission enables the service principal to\nview all queries for the warehouse\n.\nClick\nAdd\nto assign the\nCAN MANAGE\npermission to the service principal.\nPersonal access token authentication\nAWS service principal authentication\nAzure service principal authentication\nGrant permissions to crawl metadata\n(Optional) Grant permissions to query and preview data\n(Optional) Grant permissions to import and update tags\n(Optional) Grant permissions to extract lineage and usage from system tables\n(Optional) Grant view permissions to access Databricks entities via APIs\n(Optional) Grant permissions for views and materialized views\n(Optional) Grant permissions to mine query history",
    "metadata": {
      "source_url": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.html",
      "source_type": "docs",
      "file": "apps_connectors_data-warehouses_databricks_how-tos_set-up-databricks.json",
      "chunk_id": 25
    }
  }
]